{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🔬 Exploratory Data Analysis: Complete Framework\n",
    "\n",
    "<img src='https://miro.medium.com/max/1400/1*Ovy5Tif3hMrXALlgz0Jl9Q.png' width='600' alt='EDA'>\n",
    "\n",
    "## 🎯 The Art of Understanding Data\n",
    "\n",
    "**EDA is detective work!** This notebook teaches you:\n",
    "- **Systematic exploration** frameworks\n",
    "- **Visual storytelling** with data\n",
    "- **Pattern recognition** techniques\n",
    "- **Hypothesis generation** from data\n",
    "- **Business insights** extraction\n",
    "\n",
    "### 📚 What We'll Master Today:\n",
    "1. **EDA Framework** - Systematic approach\n",
    "2. **Univariate Analysis** - One variable at a time\n",
    "3. **Bivariate Analysis** - Relationships between two\n",
    "4. **Multivariate Analysis** - Complex patterns\n",
    "5. **Time Series EDA** - Temporal patterns\n",
    "6. **Text Data EDA** - Unstructured data\n",
    "7. **Automated EDA** - Tools and libraries\n",
    "8. **Business Insights** - Actionable findings\n",
    "9. **Report Generation** - Professional outputs\n",
    "10. **Complete Case Study** - Real-world project\n",
    "\n",
    "---\n",
    "\n",
    "## 🚀 Let's Explore Data Like Pros!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import essential libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style for beautiful plots\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "print(\"🔬 Exploratory Data Analysis - Ready to Explore!\")\n",
    "print(\"\\n💡 Remember: EDA is about asking questions and finding answers in data!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 📌 Section 1: EDA Framework\n",
    "\n",
    "### 🎯 Systematic Approach to Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.1 Load and Prepare Dataset\n",
    "print(\"📊 LOADING E-COMMERCE DATASET\\n\" + \"=\"*40)\n",
    "\n",
    "# Create a comprehensive e-commerce dataset\n",
    "np.random.seed(42)\n",
    "n_customers = 5000\n",
    "n_products = 100\n",
    "\n",
    "# Generate customer data\n",
    "customers = pd.DataFrame({\n",
    "    'customer_id': range(1, n_customers + 1),\n",
    "    'age': np.random.normal(35, 12, n_customers).clip(18, 80).astype(int),\n",
    "    'gender': np.random.choice(['M', 'F'], n_customers),\n",
    "    'city': np.random.choice(['New York', 'Los Angeles', 'Chicago', 'Houston', 'Phoenix'], n_customers, p=[0.3, 0.25, 0.2, 0.15, 0.1]),\n",
    "    'membership_level': np.random.choice(['Bronze', 'Silver', 'Gold', 'Platinum'], n_customers, p=[0.4, 0.3, 0.2, 0.1]),\n",
    "    'account_age_days': np.random.exponential(365, n_customers),\n",
    "    'total_spent': np.random.lognormal(6, 1.5, n_customers),\n",
    "    'num_purchases': np.random.poisson(10, n_customers),\n",
    "    'avg_rating': np.random.normal(4, 0.5, n_customers).clip(1, 5),\n",
    "    'is_subscribed': np.random.choice([0, 1], n_customers, p=[0.6, 0.4]),\n",
    "    'preferred_category': np.random.choice(['Electronics', 'Clothing', 'Home', 'Sports', 'Books'], n_customers),\n",
    "    'last_purchase_days_ago': np.random.exponential(30, n_customers),\n",
    "    'customer_lifetime_value': np.random.lognormal(7, 1, n_customers)\n",
    "})\n",
    "\n",
    "# Add some correlations\n",
    "customers['total_spent'] = customers['total_spent'] * (1 + customers['num_purchases'] * 0.1)\n",
    "customers.loc[customers['membership_level'] == 'Platinum', 'total_spent'] *= 2\n",
    "customers['churn_risk'] = (customers['last_purchase_days_ago'] > 60).astype(int)\n",
    "\n",
    "print(\"Dataset Overview:\")\n",
    "print(f\"Shape: {customers.shape}\")\n",
    "print(f\"\\nFirst 5 rows:\")\n",
    "print(customers.head())\n",
    "print(f\"\\nData Types:\")\n",
    "print(customers.dtypes)\n",
    "print(f\"\\nBasic Statistics:\")\n",
    "print(customers.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.2 EDA Framework Implementation\n",
    "print(\"🎯 SYSTEMATIC EDA FRAMEWORK\\n\" + \"=\"*40)\n",
    "\n",
    "class EDAFramework:\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        self.numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "        self.categorical_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "    \n",
    "    def basic_info(self):\n",
    "        print(\"📊 BASIC INFORMATION\")\n",
    "        print(\"=\" * 50)\n",
    "        print(f\"Rows: {len(self.df):,}\")\n",
    "        print(f\"Columns: {len(self.df.columns)}\")\n",
    "        print(f\"Numeric: {len(self.numeric_cols)}\")\n",
    "        print(f\"Categorical: {len(self.categorical_cols)}\")\n",
    "        print(f\"Memory Usage: {self.df.memory_usage().sum() / 1024**2:.2f} MB\")\n",
    "        print(f\"\\nMissing Values: {self.df.isnull().sum().sum()}\")\n",
    "        print(f\"Duplicate Rows: {self.df.duplicated().sum()}\")\n",
    "    \n",
    "    def distribution_analysis(self):\n",
    "        print(\"\\n📈 DISTRIBUTION ANALYSIS\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        for col in self.numeric_cols[:5]:  # First 5 numeric columns\n",
    "            skew = self.df[col].skew()\n",
    "            kurt = self.df[col].kurtosis()\n",
    "            print(f\"\\n{col}:\")\n",
    "            print(f\"  Mean: {self.df[col].mean():.2f}\")\n",
    "            print(f\"  Median: {self.df[col].median():.2f}\")\n",
    "            print(f\"  Std: {self.df[col].std():.2f}\")\n",
    "            print(f\"  Skewness: {skew:.2f} ({'Right' if skew > 0 else 'Left'} skewed)\")\n",
    "            print(f\"  Kurtosis: {kurt:.2f} ({'Heavy' if kurt > 0 else 'Light'} tailed)\")\n",
    "    \n",
    "    def correlation_analysis(self):\n",
    "        print(\"\\n🔗 TOP CORRELATIONS\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        corr_matrix = self.df[self.numeric_cols].corr()\n",
    "        \n",
    "        # Get top correlations\n",
    "        corr_pairs = []\n",
    "        for i in range(len(corr_matrix.columns)):\n",
    "            for j in range(i+1, len(corr_matrix.columns)):\n",
    "                corr_pairs.append((\n",
    "                    corr_matrix.columns[i],\n",
    "                    corr_matrix.columns[j],\n",
    "                    corr_matrix.iloc[i, j]\n",
    "                ))\n",
    "        \n",
    "        corr_pairs.sort(key=lambda x: abs(x[2]), reverse=True)\n",
    "        \n",
    "        for var1, var2, corr in corr_pairs[:5]:\n",
    "            print(f\"{var1} ↔ {var2}: {corr:.3f}\")\n",
    "    \n",
    "    def category_analysis(self):\n",
    "        print(\"\\n📊 CATEGORICAL ANALYSIS\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        for col in self.categorical_cols:\n",
    "            print(f\"\\n{col}:\")\n",
    "            value_counts = self.df[col].value_counts()\n",
    "            print(f\"  Unique Values: {self.df[col].nunique()}\")\n",
    "            print(f\"  Most Common: {value_counts.index[0]} ({value_counts.iloc[0]:,} occurrences)\")\n",
    "            print(f\"  Distribution:\")\n",
    "            for val, count in value_counts.head(3).items():\n",
    "                print(f\"    {val}: {count/len(self.df)*100:.1f}%\")\n",
    "\n",
    "# Run EDA Framework\n",
    "eda = EDAFramework(customers)\n",
    "eda.basic_info()\n",
    "eda.distribution_analysis()\n",
    "eda.correlation_analysis()\n",
    "eda.category_analysis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 📌 Section 2: Univariate Analysis\n",
    "\n",
    "### 🎯 Deep Dive into Individual Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1 Comprehensive Univariate Analysis\n",
    "print(\"📊 UNIVARIATE ANALYSIS\\n\" + \"=\"*40)\n",
    "\n",
    "# Select key variables for analysis\n",
    "univariate_vars = ['age', 'total_spent', 'num_purchases', 'membership_level']\n",
    "\n",
    "fig, axes = plt.subplots(4, 4, figsize=(16, 16))\n",
    "\n",
    "for idx, var in enumerate(univariate_vars):\n",
    "    row = idx\n",
    "    \n",
    "    if var in customers.select_dtypes(include=[np.number]).columns:\n",
    "        # Histogram\n",
    "        ax = axes[row, 0]\n",
    "        ax.hist(customers[var], bins=30, edgecolor='black', alpha=0.7)\n",
    "        ax.set_title(f'{var} - Histogram')\n",
    "        ax.set_xlabel(var)\n",
    "        ax.set_ylabel('Frequency')\n",
    "        \n",
    "        # Box plot\n",
    "        ax = axes[row, 1]\n",
    "        ax.boxplot(customers[var].dropna())\n",
    "        ax.set_title(f'{var} - Box Plot')\n",
    "        ax.set_ylabel(var)\n",
    "        \n",
    "        # Q-Q plot\n",
    "        ax = axes[row, 2]\n",
    "        stats.probplot(customers[var].dropna(), dist=\"norm\", plot=ax)\n",
    "        ax.set_title(f'{var} - Q-Q Plot')\n",
    "        \n",
    "        # CDF\n",
    "        ax = axes[row, 3]\n",
    "        sorted_data = np.sort(customers[var].dropna())\n",
    "        cdf = np.arange(1, len(sorted_data) + 1) / len(sorted_data)\n",
    "        ax.plot(sorted_data, cdf, linewidth=2)\n",
    "        ax.set_title(f'{var} - CDF')\n",
    "        ax.set_xlabel(var)\n",
    "        ax.set_ylabel('Cumulative Probability')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        \n",
    "    else:  # Categorical variable\n",
    "        # Bar chart\n",
    "        ax = axes[row, 0]\n",
    "        customers[var].value_counts().plot(kind='bar', ax=ax)\n",
    "        ax.set_title(f'{var} - Bar Chart')\n",
    "        ax.set_xlabel(var)\n",
    "        ax.set_ylabel('Count')\n",
    "        \n",
    "        # Pie chart\n",
    "        ax = axes[row, 1]\n",
    "        customers[var].value_counts().plot(kind='pie', ax=ax, autopct='%1.1f%%')\n",
    "        ax.set_title(f'{var} - Pie Chart')\n",
    "        \n",
    "        # Hide unused subplots for categorical\n",
    "        axes[row, 2].axis('off')\n",
    "        axes[row, 3].axis('off')\n",
    "\n",
    "plt.suptitle('Univariate Analysis Dashboard', fontsize=16, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Statistical tests for normality\n",
    "print(\"\\n📊 Normality Tests:\")\n",
    "for col in ['age', 'total_spent', 'num_purchases']:\n",
    "    stat, p_value = stats.shapiro(customers[col].dropna().sample(min(5000, len(customers))))\n",
    "    print(f\"{col}: Shapiro-Wilk p-value = {p_value:.4f} ({'Normal' if p_value > 0.05 else 'Not Normal'})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 📌 Section 3: Bivariate Analysis\n",
    "\n",
    "### 🎯 Understanding Relationships Between Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.1 Bivariate Relationships\n",
    "print(\"🔗 BIVARIATE ANALYSIS\\n\" + \"=\"*40)\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "# Numeric vs Numeric\n",
    "ax = axes[0, 0]\n",
    "ax.scatter(customers['age'], customers['total_spent'], alpha=0.5)\n",
    "ax.set_xlabel('Age')\n",
    "ax.set_ylabel('Total Spent')\n",
    "ax.set_title('Age vs Total Spent')\n",
    "z = np.polyfit(customers['age'], customers['total_spent'], 1)\n",
    "p = np.poly1d(z)\n",
    "ax.plot(customers['age'].sort_values(), p(customers['age'].sort_values()), \n",
    "        'r-', linewidth=2, alpha=0.7)\n",
    "\n",
    "# Categorical vs Numeric\n",
    "ax = axes[0, 1]\n",
    "customers.boxplot(column='total_spent', by='membership_level', ax=ax)\n",
    "ax.set_title('Total Spent by Membership Level')\n",
    "ax.set_xlabel('Membership Level')\n",
    "ax.set_ylabel('Total Spent')\n",
    "plt.sca(ax)\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Categorical vs Categorical\n",
    "ax = axes[0, 2]\n",
    "cross_tab = pd.crosstab(customers['gender'], customers['preferred_category'])\n",
    "cross_tab.plot(kind='bar', stacked=True, ax=ax)\n",
    "ax.set_title('Gender vs Preferred Category')\n",
    "ax.set_xlabel('Gender')\n",
    "ax.set_ylabel('Count')\n",
    "ax.legend(title='Category', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "# Hexbin for large datasets\n",
    "ax = axes[1, 0]\n",
    "hexbin = ax.hexbin(customers['num_purchases'], customers['total_spent'], \n",
    "                    gridsize=20, cmap='YlOrRd')\n",
    "ax.set_xlabel('Number of Purchases')\n",
    "ax.set_ylabel('Total Spent')\n",
    "ax.set_title('Purchases vs Spending (Hexbin)')\n",
    "plt.colorbar(hexbin, ax=ax)\n",
    "\n",
    "# Violin plot\n",
    "ax = axes[1, 1]\n",
    "membership_order = ['Bronze', 'Silver', 'Gold', 'Platinum']\n",
    "for i, level in enumerate(membership_order):\n",
    "    data = customers[customers['membership_level'] == level]['avg_rating']\n",
    "    parts = ax.violinplot([data.values], positions=[i], showmeans=True)\n",
    "ax.set_xticks(range(len(membership_order)))\n",
    "ax.set_xticklabels(membership_order)\n",
    "ax.set_xlabel('Membership Level')\n",
    "ax.set_ylabel('Average Rating')\n",
    "ax.set_title('Rating Distribution by Membership')\n",
    "\n",
    "# Joint plot equivalent\n",
    "ax = axes[1, 2]\n",
    "ax.scatter(customers['account_age_days'], customers['customer_lifetime_value'], \n",
    "          alpha=0.3, s=10)\n",
    "ax.set_xlabel('Account Age (days)')\n",
    "ax.set_ylabel('Customer Lifetime Value')\n",
    "ax.set_title('Account Age vs CLV')\n",
    "ax.set_xscale('log')\n",
    "ax.set_yscale('log')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Correlation analysis\n",
    "print(\"\\n📊 Correlation Analysis:\")\n",
    "numeric_cols = customers.select_dtypes(include=[np.number]).columns\n",
    "for col1 in numeric_cols[:3]:\n",
    "    for col2 in numeric_cols[3:6]:\n",
    "        corr, p_value = stats.pearsonr(customers[col1], customers[col2])\n",
    "        print(f\"{col1} vs {col2}: r={corr:.3f}, p={p_value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 📌 Section 4: Multivariate Analysis\n",
    "\n",
    "### 🎯 Complex Patterns and Interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.1 Multivariate Analysis\n",
    "print(\"🔄 MULTIVARIATE ANALYSIS\\n\" + \"=\"*40)\n",
    "\n",
    "# Correlation heatmap\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n",
    "\n",
    "# Correlation matrix\n",
    "ax = axes[0, 0]\n",
    "numeric_data = customers.select_dtypes(include=[np.number])\n",
    "corr_matrix = numeric_data.corr()\n",
    "sns.heatmap(corr_matrix, annot=True, fmt='.2f', cmap='coolwarm', \n",
    "            center=0, ax=ax, square=True)\n",
    "ax.set_title('Correlation Heatmap')\n",
    "\n",
    "# Pair plot alternative (selected variables)\n",
    "ax = axes[0, 1]\n",
    "selected_vars = ['age', 'total_spent', 'num_purchases']\n",
    "for i, var1 in enumerate(selected_vars):\n",
    "    for j, var2 in enumerate(selected_vars):\n",
    "        if i != j:\n",
    "            ax.scatter(customers[var1], customers[var2], \n",
    "                      alpha=0.1, s=1, label=f'{var1} vs {var2}')\n",
    "ax.set_title('Multi-variable Scatter')\n",
    "ax.set_xlabel('Normalized Values')\n",
    "ax.set_ylabel('Normalized Values')\n",
    "\n",
    "# 3D scatter plot\n",
    "ax = fig.add_subplot(223, projection='3d')\n",
    "scatter = ax.scatter(customers['age'], \n",
    "                     customers['num_purchases'], \n",
    "                     customers['total_spent'],\n",
    "                     c=customers['customer_lifetime_value'],\n",
    "                     cmap='viridis', s=10, alpha=0.6)\n",
    "ax.set_xlabel('Age')\n",
    "ax.set_ylabel('Num Purchases')\n",
    "ax.set_zlabel('Total Spent')\n",
    "ax.set_title('3D: Age, Purchases, Spending (colored by CLV)')\n",
    "plt.colorbar(scatter, ax=ax, pad=0.1)\n",
    "\n",
    "# Parallel coordinates\n",
    "ax = axes[1, 1]\n",
    "# Normalize data for parallel coordinates\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "normalized = scaler.fit_transform(customers[['age', 'total_spent', 'num_purchases', 'avg_rating']])\n",
    "normalized_df = pd.DataFrame(normalized, columns=['age', 'total_spent', 'num_purchases', 'avg_rating'])\n",
    "normalized_df['membership'] = customers['membership_level'].values\n",
    "\n",
    "# Plot lines for each membership level\n",
    "colors = {'Bronze': 'brown', 'Silver': 'silver', 'Gold': 'gold', 'Platinum': 'purple'}\n",
    "for level in colors:\n",
    "    subset = normalized_df[normalized_df['membership'] == level]\n",
    "    for idx in subset.index[:50]:  # Plot first 50 of each\n",
    "        ax.plot(range(4), subset.loc[idx, ['age', 'total_spent', 'num_purchases', 'avg_rating']], \n",
    "               color=colors[level], alpha=0.1)\n",
    "\n",
    "ax.set_xticks(range(4))\n",
    "ax.set_xticklabels(['Age', 'Spent', 'Purchases', 'Rating'])\n",
    "ax.set_ylabel('Standardized Value')\n",
    "ax.set_title('Parallel Coordinates by Membership')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# PCA Analysis\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "print(\"\\n📊 PCA Analysis:\")\n",
    "pca = PCA()\n",
    "numeric_scaled = scaler.fit_transform(numeric_data)\n",
    "pca_result = pca.fit_transform(numeric_scaled)\n",
    "\n",
    "explained_var = pca.explained_variance_ratio_\n",
    "cumsum_var = np.cumsum(explained_var)\n",
    "\n",
    "print(\"Explained Variance by Component:\")\n",
    "for i in range(min(5, len(explained_var))):\n",
    "    print(f\"PC{i+1}: {explained_var[i]*100:.2f}% (Cumulative: {cumsum_var[i]*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 📌 Section 5: Advanced Visualizations\n",
    "\n",
    "### 🎯 Interactive and Advanced Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.1 Interactive Visualizations with Plotly\n",
    "print(\"🎨 INTERACTIVE VISUALIZATIONS\\n\" + \"=\"*40)\n",
    "\n",
    "# Interactive scatter plot\n",
    "fig1 = px.scatter(customers, \n",
    "                  x='age', \n",
    "                  y='total_spent',\n",
    "                  color='membership_level',\n",
    "                  size='num_purchases',\n",
    "                  hover_data=['customer_id', 'city', 'preferred_category'],\n",
    "                  title='Customer Analysis: Age vs Spending',\n",
    "                  labels={'total_spent': 'Total Spent ($)',\n",
    "                         'age': 'Age (years)'},\n",
    "                  color_discrete_map={'Bronze': 'brown', \n",
    "                                      'Silver': 'silver',\n",
    "                                      'Gold': 'gold',\n",
    "                                      'Platinum': 'purple'})\n",
    "fig1.show()\n",
    "\n",
    "# Sunburst chart\n",
    "sunburst_data = customers.groupby(['city', 'preferred_category', 'membership_level']).size().reset_index(name='count')\n",
    "fig2 = px.sunburst(sunburst_data,\n",
    "                   path=['city', 'preferred_category', 'membership_level'],\n",
    "                   values='count',\n",
    "                   title='Customer Distribution Hierarchy')\n",
    "fig2.show()\n",
    "\n",
    "# 3D scatter\n",
    "fig3 = px.scatter_3d(customers.sample(1000),  # Sample for performance\n",
    "                      x='age',\n",
    "                      y='total_spent',\n",
    "                      z='customer_lifetime_value',\n",
    "                      color='churn_risk',\n",
    "                      title='3D Customer Analysis',\n",
    "                      labels={'churn_risk': 'Churn Risk'})\n",
    "fig3.show()\n",
    "\n",
    "# Box plot with all points\n",
    "fig4 = px.box(customers,\n",
    "              x='membership_level',\n",
    "              y='total_spent',\n",
    "              color='gender',\n",
    "              title='Spending by Membership and Gender',\n",
    "              points='all',\n",
    "              hover_data=['customer_id'])\n",
    "fig4.show()\n",
    "\n",
    "print(\"✅ Interactive visualizations created!\")\n",
    "print(\"💡 Hover over points for details, use controls to zoom/pan\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 📌 Section 6: Statistical Analysis\n",
    "\n",
    "### 🎯 Statistical Tests and Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.1 Statistical Tests\n",
    "print(\"📊 STATISTICAL ANALYSIS\\n\" + \"=\"*40)\n",
    "\n",
    "# T-test: Gender differences in spending\n",
    "male_spending = customers[customers['gender'] == 'M']['total_spent']\n",
    "female_spending = customers[customers['gender'] == 'F']['total_spent']\n",
    "t_stat, p_value = stats.ttest_ind(male_spending, female_spending)\n",
    "\n",
    "print(\"T-Test: Gender Differences in Spending\")\n",
    "print(f\"Male avg: ${male_spending.mean():.2f}\")\n",
    "print(f\"Female avg: ${female_spending.mean():.2f}\")\n",
    "print(f\"T-statistic: {t_stat:.3f}\")\n",
    "print(f\"P-value: {p_value:.4f}\")\n",
    "print(f\"Result: {'Significant' if p_value < 0.05 else 'Not significant'} difference\\n\")\n",
    "\n",
    "# ANOVA: Membership levels\n",
    "membership_groups = [customers[customers['membership_level'] == level]['total_spent'].values \n",
    "                    for level in ['Bronze', 'Silver', 'Gold', 'Platinum']]\n",
    "f_stat, p_value = stats.f_oneway(*membership_groups)\n",
    "\n",
    "print(\"ANOVA: Spending Across Membership Levels\")\n",
    "print(f\"F-statistic: {f_stat:.3f}\")\n",
    "print(f\"P-value: {p_value:.4f}\")\n",
    "print(f\"Result: {'Significant' if p_value < 0.05 else 'Not significant'} difference\\n\")\n",
    "\n",
    "# Chi-square test: Gender vs Preferred Category\n",
    "contingency_table = pd.crosstab(customers['gender'], customers['preferred_category'])\n",
    "chi2, p_value, dof, expected = stats.chi2_contingency(contingency_table)\n",
    "\n",
    "print(\"Chi-Square: Gender vs Preferred Category\")\n",
    "print(f\"Chi-square statistic: {chi2:.3f}\")\n",
    "print(f\"P-value: {p_value:.4f}\")\n",
    "print(f\"Result: {'Dependent' if p_value < 0.05 else 'Independent'} relationship\\n\")\n",
    "\n",
    "# Correlation tests\n",
    "print(\"Correlation Tests:\")\n",
    "correlations = [\n",
    "    ('Age', 'Total Spent', customers['age'], customers['total_spent']),\n",
    "    ('Num Purchases', 'Total Spent', customers['num_purchases'], customers['total_spent']),\n",
    "    ('Account Age', 'CLV', customers['account_age_days'], customers['customer_lifetime_value'])\n",
    "]\n",
    "\n",
    "for name1, name2, var1, var2 in correlations:\n",
    "    corr, p_val = stats.pearsonr(var1, var2)\n",
    "    print(f\"{name1} vs {name2}: r={corr:.3f}, p={p_val:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 📌 Section 7: Segmentation Analysis\n",
    "\n",
    "### 🎯 Finding Customer Segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.1 Customer Segmentation\n",
    "print(\"👥 CUSTOMER SEGMENTATION\\n\" + \"=\"*40)\n",
    "\n",
    "# RFM Analysis\n",
    "customers['recency_score'] = pd.qcut(customers['last_purchase_days_ago'], 4, \n",
    "                                      labels=['4', '3', '2', '1'])  # 4 is best (most recent)\n",
    "customers['frequency_score'] = pd.qcut(customers['num_purchases'], 4, \n",
    "                                       labels=['1', '2', '3', '4'])  # 4 is best (most frequent)\n",
    "customers['monetary_score'] = pd.qcut(customers['total_spent'], 4, \n",
    "                                      labels=['1', '2', '3', '4'])  # 4 is best (highest value)\n",
    "\n",
    "customers['rfm_score'] = (customers['recency_score'].astype(str) + \n",
    "                          customers['frequency_score'].astype(str) + \n",
    "                          customers['monetary_score'].astype(str))\n",
    "\n",
    "# Define segments\n",
    "def segment_customers(rfm):\n",
    "    if rfm in ['444', '443', '434', '344']:\n",
    "        return 'Champions'\n",
    "    elif rfm in ['442', '441', '432', '431', '342', '341', '332', '331']:\n",
    "        return 'Loyal Customers'\n",
    "    elif rfm in ['424', '423', '414', '413', '324', '323']:\n",
    "        return 'Potential Loyalists'\n",
    "    elif rfm in ['422', '421', '412', '411', '322', '321', '312', '311']:\n",
    "        return 'New Customers'\n",
    "    elif rfm in ['244', '243', '234', '144', '143', '134']:\n",
    "        return 'At Risk'\n",
    "    elif rfm in ['242', '241', '232', '231', '142', '141', '132', '131']:\n",
    "        return 'Cant Lose Them'\n",
    "    else:\n",
    "        return 'Lost'\n",
    "\n",
    "customers['segment'] = customers['rfm_score'].apply(segment_customers)\n",
    "\n",
    "# Visualize segments\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Segment distribution\n",
    "ax = axes[0, 0]\n",
    "segment_counts = customers['segment'].value_counts()\n",
    "ax.pie(segment_counts.values, labels=segment_counts.index, autopct='%1.1f%%')\n",
    "ax.set_title('Customer Segment Distribution')\n",
    "\n",
    "# Segment characteristics\n",
    "ax = axes[0, 1]\n",
    "segment_stats = customers.groupby('segment')['total_spent'].agg(['mean', 'median'])\n",
    "segment_stats.plot(kind='bar', ax=ax)\n",
    "ax.set_title('Average Spending by Segment')\n",
    "ax.set_xlabel('Segment')\n",
    "ax.set_ylabel('Spending ($)')\n",
    "plt.sca(ax)\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Scatter plot colored by segment\n",
    "ax = axes[1, 0]\n",
    "for segment in customers['segment'].unique():\n",
    "    mask = customers['segment'] == segment\n",
    "    ax.scatter(customers.loc[mask, 'num_purchases'],\n",
    "              customers.loc[mask, 'total_spent'],\n",
    "              label=segment, alpha=0.6, s=20)\n",
    "ax.set_xlabel('Number of Purchases')\n",
    "ax.set_ylabel('Total Spent ($)')\n",
    "ax.set_title('Segments: Purchases vs Spending')\n",
    "ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "# Segment metrics\n",
    "ax = axes[1, 1]\n",
    "segment_summary = customers.groupby('segment').agg({\n",
    "    'customer_id': 'count',\n",
    "    'total_spent': 'sum',\n",
    "    'churn_risk': 'mean'\n",
    "}).rename(columns={'customer_id': 'count'})\n",
    "\n",
    "segment_summary['value_contribution'] = (segment_summary['total_spent'] / \n",
    "                                         segment_summary['total_spent'].sum() * 100)\n",
    "\n",
    "ax.axis('tight')\n",
    "ax.axis('off')\n",
    "table_data = segment_summary[['count', 'value_contribution', 'churn_risk']].round(2)\n",
    "table = ax.table(cellText=table_data.values,\n",
    "                rowLabels=table_data.index,\n",
    "                colLabels=['Count', 'Value %', 'Churn Risk'],\n",
    "                cellLoc='center',\n",
    "                loc='center')\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(10)\n",
    "ax.set_title('Segment Metrics Summary')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n📊 Segment Summary:\")\n",
    "for segment in segment_counts.index[:5]:\n",
    "    segment_data = customers[customers['segment'] == segment]\n",
    "    print(f\"\\n{segment}:\")\n",
    "    print(f\"  Count: {len(segment_data):,}\")\n",
    "    print(f\"  Avg Spending: ${segment_data['total_spent'].mean():.2f}\")\n",
    "    print(f\"  Churn Risk: {segment_data['churn_risk'].mean()*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 📌 Section 8: Time-Based Analysis\n",
    "\n",
    "### 🎯 Temporal Patterns and Trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8.1 Time-Based Analysis\n",
    "print(\"📅 TIME-BASED ANALYSIS\\n\" + \"=\"*40)\n",
    "\n",
    "# Create time-based features\n",
    "customers['account_age_months'] = customers['account_age_days'] / 30\n",
    "customers['cohort'] = pd.cut(customers['account_age_months'], \n",
    "                             bins=[0, 3, 6, 12, 24, 100],\n",
    "                             labels=['0-3m', '3-6m', '6-12m', '1-2y', '2y+'])\n",
    "\n",
    "# Cohort analysis\n",
    "cohort_stats = customers.groupby('cohort').agg({\n",
    "    'customer_id': 'count',\n",
    "    'total_spent': 'mean',\n",
    "    'num_purchases': 'mean',\n",
    "    'churn_risk': 'mean',\n",
    "    'avg_rating': 'mean'\n",
    "}).rename(columns={'customer_id': 'count'})\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Cohort sizes\n",
    "ax = axes[0, 0]\n",
    "cohort_stats['count'].plot(kind='bar', ax=ax, color='skyblue')\n",
    "ax.set_title('Customer Distribution by Account Age')\n",
    "ax.set_xlabel('Cohort')\n",
    "ax.set_ylabel('Number of Customers')\n",
    "plt.sca(ax)\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Spending by cohort\n",
    "ax = axes[0, 1]\n",
    "cohort_stats['total_spent'].plot(kind='line', marker='o', ax=ax, linewidth=2)\n",
    "ax.set_title('Average Spending by Cohort')\n",
    "ax.set_xlabel('Cohort')\n",
    "ax.set_ylabel('Average Spending ($)')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Churn risk by cohort\n",
    "ax = axes[1, 0]\n",
    "cohort_stats['churn_risk'].plot(kind='bar', ax=ax, color='coral')\n",
    "ax.set_title('Churn Risk by Cohort')\n",
    "ax.set_xlabel('Cohort')\n",
    "ax.set_ylabel('Churn Risk')\n",
    "plt.sca(ax)\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Retention curve\n",
    "ax = axes[1, 1]\n",
    "retention_data = []\n",
    "for days in range(0, 365, 30):\n",
    "    active = (customers['last_purchase_days_ago'] <= days).mean()\n",
    "    retention_data.append((days, active))\n",
    "\n",
    "days, retention = zip(*retention_data)\n",
    "ax.plot(days, retention, 'b-', linewidth=2, marker='o')\n",
    "ax.set_xlabel('Days Since Last Purchase')\n",
    "ax.set_ylabel('Retention Rate')\n",
    "ax.set_title('Customer Retention Curve')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n📊 Cohort Analysis Summary:\")\n",
    "print(cohort_stats.round(2).to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 📌 Section 9: Automated EDA Tools\n",
    "\n",
    "### 🎯 Quick EDA with Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9.1 Automated EDA\n",
    "print(\"🤖 AUTOMATED EDA TOOLS\\n\" + \"=\"*40)\n",
    "\n",
    "# Quick statistical summary\n",
    "def automated_eda_summary(df):\n",
    "    \"\"\"Generate comprehensive EDA summary\"\"\"\n",
    "    \n",
    "    summary = {\n",
    "        'shape': df.shape,\n",
    "        'dtypes': df.dtypes.value_counts().to_dict(),\n",
    "        'missing': df.isnull().sum().sum(),\n",
    "        'duplicates': df.duplicated().sum(),\n",
    "        'numeric_cols': len(df.select_dtypes(include=[np.number]).columns),\n",
    "        'categorical_cols': len(df.select_dtypes(include=['object']).columns)\n",
    "    }\n",
    "    \n",
    "    # Numeric summary\n",
    "    numeric_summary = df.describe()\n",
    "    \n",
    "    # Categorical summary\n",
    "    categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "    categorical_summary = {}\n",
    "    for col in categorical_cols:\n",
    "        categorical_summary[col] = {\n",
    "            'unique': df[col].nunique(),\n",
    "            'most_common': df[col].mode()[0] if not df[col].mode().empty else None,\n",
    "            'frequency': df[col].value_counts().iloc[0] if len(df[col].value_counts()) > 0 else 0\n",
    "        }\n",
    "    \n",
    "    # Correlation insights\n",
    "    numeric_df = df.select_dtypes(include=[np.number])\n",
    "    if not numeric_df.empty:\n",
    "        corr_matrix = numeric_df.corr()\n",
    "        high_corr = []\n",
    "        for i in range(len(corr_matrix.columns)):\n",
    "            for j in range(i+1, len(corr_matrix.columns)):\n",
    "                if abs(corr_matrix.iloc[i, j]) > 0.7:\n",
    "                    high_corr.append((corr_matrix.columns[i], \n",
    "                                    corr_matrix.columns[j], \n",
    "                                    corr_matrix.iloc[i, j]))\n",
    "        summary['high_correlations'] = high_corr\n",
    "    \n",
    "    # Outlier detection\n",
    "    outliers = {}\n",
    "    for col in numeric_df.columns:\n",
    "        Q1 = numeric_df[col].quantile(0.25)\n",
    "        Q3 = numeric_df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        outlier_count = ((numeric_df[col] < Q1 - 1.5*IQR) | \n",
    "                        (numeric_df[col] > Q3 + 1.5*IQR)).sum()\n",
    "        if outlier_count > 0:\n",
    "            outliers[col] = outlier_count\n",
    "    summary['outliers'] = outliers\n",
    "    \n",
    "    return summary, numeric_summary, categorical_summary\n",
    "\n",
    "# Run automated EDA\n",
    "summary, numeric_summary, categorical_summary = automated_eda_summary(customers)\n",
    "\n",
    "print(\"📊 Dataset Overview:\")\n",
    "print(f\"Shape: {summary['shape']}\")\n",
    "print(f\"Data Types: {summary['dtypes']}\")\n",
    "print(f\"Missing Values: {summary['missing']}\")\n",
    "print(f\"Duplicates: {summary['duplicates']}\")\n",
    "\n",
    "print(\"\\n📈 Numeric Variables Summary:\")\n",
    "print(numeric_summary.round(2))\n",
    "\n",
    "print(\"\\n📊 Categorical Variables:\")\n",
    "for col, stats in categorical_summary.items():\n",
    "    print(f\"{col}: {stats['unique']} unique, most common: {stats['most_common']}\")\n",
    "\n",
    "print(\"\\n🔗 High Correlations (|r| > 0.7):\")\n",
    "for var1, var2, corr in summary.get('high_correlations', []):\n",
    "    print(f\"{var1} ↔ {var2}: {corr:.3f}\")\n",
    "\n",
    "print(\"\\n🔍 Outliers Detected:\")\n",
    "for col, count in summary.get('outliers', {}).items():\n",
    "    print(f\"{col}: {count} outliers\")\n",
    "\n",
    "# Quick visualization dashboard\n",
    "def create_eda_dashboard(df):\n",
    "    \"\"\"Create automated visualization dashboard\"\"\"\n",
    "    \n",
    "    numeric_cols = df.select_dtypes(include=[np.number]).columns[:4]\n",
    "    categorical_cols = df.select_dtypes(include=['object']).columns[:2]\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    # Numeric distributions\n",
    "    for i, col in enumerate(numeric_cols):\n",
    "        axes[i].hist(df[col], bins=30, edgecolor='black', alpha=0.7)\n",
    "        axes[i].set_title(f'{col} Distribution')\n",
    "        axes[i].set_xlabel(col)\n",
    "        axes[i].set_ylabel('Frequency')\n",
    "    \n",
    "    # Categorical distributions\n",
    "    for i, col in enumerate(categorical_cols):\n",
    "        df[col].value_counts()[:10].plot(kind='bar', ax=axes[4+i])\n",
    "        axes[4+i].set_title(f'{col} Distribution')\n",
    "        axes[4+i].set_xlabel(col)\n",
    "        axes[4+i].set_ylabel('Count')\n",
    "    \n",
    "    plt.suptitle('Automated EDA Dashboard', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "create_eda_dashboard(customers)\n",
    "\n",
    "print(\"\\n💡 Automated EDA Complete!\")\n",
    "print(\"For more detailed analysis, consider using:\")\n",
    "print(\"  • pandas-profiling\")\n",
    "print(\"  • sweetviz\")\n",
    "print(\"  • autoviz\")\n",
    "print(\"  • dtale\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 🎯 Section 10: Business Insights & Recommendations\n",
    "\n",
    "### Translating Analysis to Action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10.1 Business Insights Generation\n",
    "print(\"💼 BUSINESS INSIGHTS & RECOMMENDATIONS\\n\" + \"=\"*50)\n",
    "\n",
    "# Key metrics calculation\n",
    "total_revenue = customers['total_spent'].sum()\n",
    "avg_customer_value = customers['customer_lifetime_value'].mean()\n",
    "churn_rate = customers['churn_risk'].mean()\n",
    "top_segment_revenue = customers.groupby('segment')['total_spent'].sum().max()\n",
    "\n",
    "print(\"📊 KEY BUSINESS METRICS:\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"Total Revenue: ${total_revenue:,.2f}\")\n",
    "print(f\"Average CLV: ${avg_customer_value:,.2f}\")\n",
    "print(f\"Churn Rate: {churn_rate*100:.1f}%\")\n",
    "print(f\"Customer Base: {len(customers):,}\")\n",
    "\n",
    "print(\"\\n🎯 KEY INSIGHTS:\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Insight 1: Revenue concentration\n",
    "top_20_pct = int(len(customers) * 0.2)\n",
    "top_20_revenue = customers.nlargest(top_20_pct, 'total_spent')['total_spent'].sum()\n",
    "revenue_concentration = top_20_revenue / total_revenue * 100\n",
    "print(f\"1. Revenue Concentration: Top 20% of customers generate {revenue_concentration:.1f}% of revenue\")\n",
    "\n",
    "# Insight 2: Segment performance\n",
    "best_segment = customers.groupby('segment')['total_spent'].mean().idxmax()\n",
    "print(f\"2. Best Segment: '{best_segment}' has highest average spending\")\n",
    "\n",
    "# Insight 3: Churn patterns\n",
    "high_risk_value = customers[customers['churn_risk'] == 1]['total_spent'].sum()\n",
    "at_risk_pct = high_risk_value / total_revenue * 100\n",
    "print(f\"3. Churn Risk: {at_risk_pct:.1f}% of revenue is at risk\")\n",
    "\n",
    "# Insight 4: Category preferences\n",
    "top_category = customers.groupby('preferred_category')['total_spent'].sum().idxmax()\n",
    "print(f\"4. Top Category: '{top_category}' generates most revenue\")\n",
    "\n",
    "# Insight 5: Membership impact\n",
    "platinum_avg = customers[customers['membership_level'] == 'Platinum']['total_spent'].mean()\n",
    "bronze_avg = customers[customers['membership_level'] == 'Bronze']['total_spent'].mean()\n",
    "membership_lift = (platinum_avg / bronze_avg - 1) * 100\n",
    "print(f\"5. Membership Value: Platinum members spend {membership_lift:.0f}% more than Bronze\")\n",
    "\n",
    "print(\"\\n💡 RECOMMENDATIONS:\")\n",
    "print(\"=\" * 40)\n",
    "recommendations = [\n",
    "    \"1. RETENTION: Launch targeted retention campaign for high-value at-risk customers\",\n",
    "    \"2. UPSELL: Create upgrade path from Bronze → Silver → Gold → Platinum\",\n",
    "    f\"3. FOCUS: Prioritize marketing for '{top_category}' category\",\n",
    "    \"4. SEGMENTATION: Develop personalized strategies for each customer segment\",\n",
    "    \"5. LOYALTY: Implement rewards program to increase purchase frequency\"\n",
    "]\n",
    "\n",
    "for rec in recommendations:\n",
    "    print(rec)\n",
    "\n",
    "# Action priority matrix\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "actions = [\n",
    "    ('Retention Campaign', 8, 9, 1000000),\n",
    "    ('Upsell Program', 7, 7, 750000),\n",
    "    ('Category Focus', 6, 8, 500000),\n",
    "    ('Personalization', 9, 6, 1200000),\n",
    "    ('Loyalty Program', 5, 9, 400000)\n",
    "]\n",
    "\n",
    "for action, impact, ease, value in actions:\n",
    "    ax.scatter(ease, impact, s=value/5000, alpha=0.6)\n",
    "    ax.annotate(action, (ease, impact), ha='center', va='center')\n",
    "\n",
    "ax.set_xlabel('Implementation Ease (1-10)', fontsize=12)\n",
    "ax.set_ylabel('Business Impact (1-10)', fontsize=12)\n",
    "ax.set_title('Action Priority Matrix\\n(Bubble size = Estimated Value)', fontsize=14)\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.set_xlim(0, 10)\n",
    "ax.set_ylim(0, 10)\n",
    "\n",
    "# Add quadrant lines\n",
    "ax.axhline(y=5, color='gray', linestyle='--', alpha=0.5)\n",
    "ax.axvline(x=5, color='gray', linestyle='--', alpha=0.5)\n",
    "\n",
    "# Add quadrant labels\n",
    "ax.text(2.5, 7.5, 'High Impact\\nHard to Implement', ha='center', alpha=0.5)\n",
    "ax.text(7.5, 7.5, 'Quick Wins', ha='center', alpha=0.5, fontweight='bold')\n",
    "ax.text(2.5, 2.5, 'Low Priority', ha='center', alpha=0.5)\n",
    "ax.text(7.5, 2.5, 'Fill-ins', ha='center', alpha=0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✅ EDA COMPLETE - Ready for modeling and implementation!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 🎯 Summary & Next Steps\n",
    "\n",
    "### 🏆 What You've Learned:\n",
    "\n",
    "✅ **EDA Framework**\n",
    "- Systematic exploration approach\n",
    "- Question-driven analysis\n",
    "- Comprehensive assessment\n",
    "\n",
    "✅ **Analysis Techniques**\n",
    "- Univariate analysis\n",
    "- Bivariate relationships\n",
    "- Multivariate patterns\n",
    "- Segmentation\n",
    "\n",
    "✅ **Visualization Mastery**\n",
    "- Static visualizations\n",
    "- Interactive plots\n",
    "- Dashboard creation\n",
    "- Business presentations\n",
    "\n",
    "✅ **Statistical Insights**\n",
    "- Hypothesis testing\n",
    "- Correlation analysis\n",
    "- Distribution assessment\n",
    "- Outlier detection\n",
    "\n",
    "✅ **Business Value**\n",
    "- Translating data to insights\n",
    "- Actionable recommendations\n",
    "- Priority matrices\n",
    "- ROI estimation\n",
    "\n",
    "### 🚀 Next Steps:\n",
    "\n",
    "1. **Practice on Real Data** - Apply to your projects\n",
    "2. **Master Pipeline Creation** - Next notebook!\n",
    "3. **Learn Feature Engineering** - Create powerful features\n",
    "4. **Study Machine Learning** - Build predictive models\n",
    "\n",
    "### 💡 Key Takeaways:\n",
    "\n",
    "- **EDA is iterative** - Keep asking questions\n",
    "- **Visualize everything** - Pictures reveal patterns\n",
    "- **Context matters** - Understand the business\n",
    "- **Document findings** - Share insights clearly\n",
    "\n",
    "---\n",
    "\n",
    "## 🎉 Congratulations!\n",
    "\n",
    "You now have a complete EDA framework!\n",
    "\n",
    "Remember: **Great analysis leads to great decisions.**\n",
    "\n",
    "**Keep exploring, keep discovering, keep innovating!** 🚀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🎊 Chapter Complete!\n",
    "print(\"🎊\" * 20)\n",
    "print(\"\\n    🏆 EXPLORATORY DATA ANALYSIS COMPLETE! 🏆\")\n",
    "print(\"\\n    You've mastered:\")\n",
    "print(\"    ✅ EDA Framework\")\n",
    "print(\"    ✅ Statistical Analysis\")\n",
    "print(\"    ✅ Advanced Visualizations\")\n",
    "print(\"    ✅ Segmentation\")\n",
    "print(\"    ✅ Business Insights\")\n",
    "print(\"\\n    Ready for: Master Pipeline Creation!\")\n",
    "print(\"\\n\" + \"🎊\" * 20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}