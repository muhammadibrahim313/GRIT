{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìà Statistics for Data Science: Complete Guide\n",
    "\n",
    "<img src='https://miro.medium.com/max/1400/1*2nqdHuEXlf8bFP8r3AcH6g.png' width='600' alt='Statistics'>\n",
    "\n",
    "## üéØ Why Statistics Matters\n",
    "\n",
    "Statistics is the **language of data**. It helps us:\n",
    "- **Understand** what data is telling us\n",
    "- **Make decisions** based on evidence\n",
    "- **Predict** future outcomes\n",
    "- **Test** hypotheses scientifically\n",
    "\n",
    "### üìö What We'll Master Today:\n",
    "1. **Descriptive Statistics** - Summarizing data\n",
    "2. **Probability Basics** - Understanding uncertainty\n",
    "3. **Distributions** - Patterns in data\n",
    "4. **Inferential Statistics** - Making conclusions\n",
    "5. **Hypothesis Testing** - Scientific decision making\n",
    "6. **Correlation & Regression** - Finding relationships\n",
    "7. **Statistical Tests** - Choosing the right test\n",
    "8. **Bayesian Thinking** - Updating beliefs\n",
    "9. **Time Series** - Analyzing trends\n",
    "10. **Business Applications** - Real-world statistics\n",
    "\n",
    "---\n",
    "\n",
    "## üöÄ Let's Make Statistics Intuitive!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import essential libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.stats import norm, t, chi2, f\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style for beautiful plots\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "print(\"üìà Statistics for Data Science - Ready to Learn!\")\n",
    "print(\"\\nüí° Remember: Statistics is about understanding patterns, not memorizing formulas!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìå Section 1: Descriptive Statistics - Understanding Your Data\n",
    "\n",
    "### üéØ The First Step in Any Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.1 Measures of Central Tendency\n",
    "print(\"üìä MEASURES OF CENTRAL TENDENCY\\n\" + \"=\"*40)\n",
    "\n",
    "# Create sample data - Employee salaries (in $1000s)\n",
    "np.random.seed(42)\n",
    "salaries = np.concatenate([\n",
    "    np.random.normal(50, 10, 80),  # Regular employees\n",
    "    np.random.normal(80, 15, 15),  # Managers\n",
    "    [150, 200, 500]  # Executives\n",
    "])\n",
    "\n",
    "# Calculate measures\n",
    "mean_salary = np.mean(salaries)\n",
    "median_salary = np.median(salaries)\n",
    "mode_salary = stats.mode(salaries, keepdims=True).mode[0]\n",
    "\n",
    "print(f\"Dataset: Employee Salaries (n={len(salaries)})\")\n",
    "print(f\"\\nüìä Central Tendency:\")\n",
    "print(f\"Mean (Average): ${mean_salary:.2f}k\")\n",
    "print(f\"Median (Middle): ${median_salary:.2f}k\")\n",
    "print(f\"Mode (Most Common): ${mode_salary:.2f}k\")\n",
    "\n",
    "# Visualize\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Histogram with measures\n",
    "ax1.hist(salaries, bins=30, alpha=0.7, edgecolor='black')\n",
    "ax1.axvline(mean_salary, color='red', linestyle='--', linewidth=2, label=f'Mean: ${mean_salary:.0f}k')\n",
    "ax1.axvline(median_salary, color='green', linestyle='--', linewidth=2, label=f'Median: ${median_salary:.0f}k')\n",
    "ax1.set_xlabel('Salary ($1000s)')\n",
    "ax1.set_ylabel('Frequency')\n",
    "ax1.set_title('Salary Distribution')\n",
    "ax1.legend()\n",
    "\n",
    "# Box plot\n",
    "ax2.boxplot(salaries, vert=False)\n",
    "ax2.set_xlabel('Salary ($1000s)')\n",
    "ax2.set_title('Box Plot: Shows Quartiles and Outliers')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüí° Insight: When data has outliers (like CEO salaries),\")\n",
    "print(\"   median is often more representative than mean!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.2 Measures of Spread\n",
    "print(\"üìè MEASURES OF SPREAD\\n\" + \"=\"*40)\n",
    "\n",
    "# Calculate spread measures\n",
    "variance = np.var(salaries)\n",
    "std_dev = np.std(salaries)\n",
    "salary_range = np.max(salaries) - np.min(salaries)\n",
    "iqr = np.percentile(salaries, 75) - np.percentile(salaries, 25)\n",
    "cv = (std_dev / mean_salary) * 100  # Coefficient of variation\n",
    "\n",
    "print(\"üìä Spread Measures:\")\n",
    "print(f\"Range: ${salary_range:.2f}k\")\n",
    "print(f\"Variance: {variance:.2f}\")\n",
    "print(f\"Standard Deviation: ${std_dev:.2f}k\")\n",
    "print(f\"IQR (Q3-Q1): ${iqr:.2f}k\")\n",
    "print(f\"Coefficient of Variation: {cv:.1f}%\")\n",
    "\n",
    "# Percentiles\n",
    "percentiles = [10, 25, 50, 75, 90]\n",
    "print(\"\\nüìä Percentiles:\")\n",
    "for p in percentiles:\n",
    "    value = np.percentile(salaries, p)\n",
    "    print(f\"{p}th percentile: ${value:.2f}k\")\n",
    "\n",
    "# Visualize spread\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "# Distribution with std bands\n",
    "ax = axes[0, 0]\n",
    "ax.hist(salaries, bins=30, alpha=0.5, density=True)\n",
    "x = np.linspace(salaries.min(), salaries.max(), 100)\n",
    "ax.plot(x, norm.pdf(x, mean_salary, std_dev), 'r-', linewidth=2)\n",
    "ax.axvline(mean_salary, color='black', linestyle='-', linewidth=2)\n",
    "ax.axvline(mean_salary - std_dev, color='red', linestyle='--', alpha=0.5)\n",
    "ax.axvline(mean_salary + std_dev, color='red', linestyle='--', alpha=0.5)\n",
    "ax.axvline(mean_salary - 2*std_dev, color='orange', linestyle='--', alpha=0.5)\n",
    "ax.axvline(mean_salary + 2*std_dev, color='orange', linestyle='--', alpha=0.5)\n",
    "ax.set_title('Distribution with Standard Deviation Bands')\n",
    "ax.set_xlabel('Salary')\n",
    "\n",
    "# Violin plot\n",
    "ax = axes[0, 1]\n",
    "ax.violinplot([salaries], showmeans=True, showmedians=True)\n",
    "ax.set_title('Violin Plot: Shows Distribution Shape')\n",
    "ax.set_ylabel('Salary')\n",
    "\n",
    "# QQ plot\n",
    "ax = axes[1, 0]\n",
    "stats.probplot(salaries, dist=\"norm\", plot=ax)\n",
    "ax.set_title('Q-Q Plot: Checking Normality')\n",
    "\n",
    "# Cumulative distribution\n",
    "ax = axes[1, 1]\n",
    "sorted_salaries = np.sort(salaries)\n",
    "cumulative = np.arange(1, len(sorted_salaries) + 1) / len(sorted_salaries)\n",
    "ax.plot(sorted_salaries, cumulative, linewidth=2)\n",
    "ax.set_xlabel('Salary')\n",
    "ax.set_ylabel('Cumulative Probability')\n",
    "ax.set_title('Cumulative Distribution Function')\n",
    "ax.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.3 Skewness and Kurtosis\n",
    "print(\"üìê SHAPE OF DISTRIBUTION\\n\" + \"=\"*40)\n",
    "\n",
    "from scipy.stats import skew, kurtosis\n",
    "\n",
    "# Calculate shape measures\n",
    "skewness = skew(salaries)\n",
    "kurt = kurtosis(salaries)\n",
    "\n",
    "print(f\"Skewness: {skewness:.3f}\")\n",
    "if skewness > 0.5:\n",
    "    print(\"  ‚Üí Positively skewed (tail on right)\")\n",
    "elif skewness < -0.5:\n",
    "    print(\"  ‚Üí Negatively skewed (tail on left)\")\n",
    "else:\n",
    "    print(\"  ‚Üí Approximately symmetric\")\n",
    "\n",
    "print(f\"\\nKurtosis: {kurt:.3f}\")\n",
    "if kurt > 0:\n",
    "    print(\"  ‚Üí Heavy tails (more outliers than normal)\")\n",
    "elif kurt < 0:\n",
    "    print(\"  ‚Üí Light tails (fewer outliers than normal)\")\n",
    "else:\n",
    "    print(\"  ‚Üí Similar to normal distribution\")\n",
    "\n",
    "# Create different distributions for comparison\n",
    "np.random.seed(42)\n",
    "normal_dist = np.random.normal(0, 1, 1000)\n",
    "skewed_dist = np.random.gamma(2, 2, 1000)\n",
    "heavy_tail = np.random.standard_t(3, 1000)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "distributions = [normal_dist, skewed_dist, heavy_tail]\n",
    "titles = ['Normal (Symmetric)', 'Positively Skewed', 'Heavy Tails']\n",
    "\n",
    "for ax, dist, title in zip(axes, distributions, titles):\n",
    "    ax.hist(dist, bins=30, alpha=0.7, edgecolor='black')\n",
    "    ax.axvline(np.mean(dist), color='red', linestyle='--', label='Mean')\n",
    "    ax.axvline(np.median(dist), color='green', linestyle='--', label='Median')\n",
    "    ax.set_title(f'{title}\\nSkew: {skew(dist):.2f}, Kurt: {kurtosis(dist):.2f}')\n",
    "    ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìå Section 2: Probability Basics - Understanding Uncertainty\n",
    "\n",
    "### üéØ The Foundation of Statistical Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1 Basic Probability Concepts\n",
    "print(\"üé≤ PROBABILITY BASICS\\n\" + \"=\"*40)\n",
    "\n",
    "# Simulate coin flips\n",
    "np.random.seed(42)\n",
    "n_flips = 1000\n",
    "coin_flips = np.random.choice(['Heads', 'Tails'], n_flips)\n",
    "\n",
    "# Calculate probabilities\n",
    "p_heads = np.sum(coin_flips == 'Heads') / n_flips\n",
    "p_tails = np.sum(coin_flips == 'Tails') / n_flips\n",
    "\n",
    "print(f\"Coin Flip Experiment ({n_flips} flips):\")\n",
    "print(f\"P(Heads) = {p_heads:.3f}\")\n",
    "print(f\"P(Tails) = {p_tails:.3f}\")\n",
    "\n",
    "# Law of Large Numbers\n",
    "cumulative_heads = np.cumsum(coin_flips == 'Heads')\n",
    "cumulative_prob = cumulative_heads / np.arange(1, n_flips + 1)\n",
    "\n",
    "# Visualize\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Law of Large Numbers\n",
    "ax1.plot(cumulative_prob[:100], label='First 100 flips', alpha=0.7)\n",
    "ax1.plot(cumulative_prob, label='All flips', linewidth=2)\n",
    "ax1.axhline(y=0.5, color='red', linestyle='--', label='True probability')\n",
    "ax1.set_xlabel('Number of Flips')\n",
    "ax1.set_ylabel('Probability of Heads')\n",
    "ax1.set_title('Law of Large Numbers')\n",
    "ax1.legend()\n",
    "ax1.grid(True)\n",
    "\n",
    "# Dice rolls - Multiple outcomes\n",
    "n_rolls = 10000\n",
    "dice_rolls = np.random.randint(1, 7, n_rolls)\n",
    "unique, counts = np.unique(dice_rolls, return_counts=True)\n",
    "\n",
    "ax2.bar(unique, counts/n_rolls, alpha=0.7)\n",
    "ax2.axhline(y=1/6, color='red', linestyle='--', label='Expected probability')\n",
    "ax2.set_xlabel('Dice Face')\n",
    "ax2.set_ylabel('Probability')\n",
    "ax2.set_title('Fair Dice Probabilities')\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.2 Conditional Probability and Bayes' Theorem\n",
    "print(\"üîÑ CONDITIONAL PROBABILITY & BAYES\\n\" + \"=\"*40)\n",
    "\n",
    "# Medical test example\n",
    "# Disease prevalence: 1%\n",
    "# Test sensitivity (true positive rate): 95%\n",
    "# Test specificity (true negative rate): 90%\n",
    "\n",
    "p_disease = 0.01\n",
    "p_no_disease = 1 - p_disease\n",
    "p_positive_given_disease = 0.95  # Sensitivity\n",
    "p_negative_given_no_disease = 0.90  # Specificity\n",
    "p_positive_given_no_disease = 1 - p_negative_given_no_disease\n",
    "\n",
    "# Bayes' Theorem\n",
    "# P(Disease|Positive) = P(Positive|Disease) * P(Disease) / P(Positive)\n",
    "\n",
    "p_positive = (p_positive_given_disease * p_disease + \n",
    "              p_positive_given_no_disease * p_no_disease)\n",
    "\n",
    "p_disease_given_positive = (p_positive_given_disease * p_disease) / p_positive\n",
    "\n",
    "print(\"Medical Test Example:\")\n",
    "print(f\"Disease prevalence: {p_disease*100:.1f}%\")\n",
    "print(f\"Test sensitivity: {p_positive_given_disease*100:.0f}%\")\n",
    "print(f\"Test specificity: {p_negative_given_no_disease*100:.0f}%\")\n",
    "print(f\"\\nIf test is positive:\")\n",
    "print(f\"Probability of having disease: {p_disease_given_positive*100:.1f}%\")\n",
    "print(f\"\\nüí° Surprising: Even with a positive test, probability is only {p_disease_given_positive*100:.1f}%!\")\n",
    "\n",
    "# Simulate population\n",
    "population_size = 10000\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generate true disease status\n",
    "has_disease = np.random.random(population_size) < p_disease\n",
    "\n",
    "# Generate test results\n",
    "test_results = np.zeros(population_size, dtype=bool)\n",
    "# For those with disease\n",
    "test_results[has_disease] = np.random.random(np.sum(has_disease)) < p_positive_given_disease\n",
    "# For those without disease\n",
    "test_results[~has_disease] = np.random.random(np.sum(~has_disease)) < p_positive_given_no_disease\n",
    "\n",
    "# Create confusion matrix\n",
    "true_positive = np.sum(has_disease & test_results)\n",
    "false_positive = np.sum(~has_disease & test_results)\n",
    "true_negative = np.sum(~has_disease & ~test_results)\n",
    "false_negative = np.sum(has_disease & ~test_results)\n",
    "\n",
    "# Visualize\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Confusion matrix\n",
    "confusion = np.array([[true_negative, false_positive],\n",
    "                      [false_negative, true_positive]])\n",
    "sns.heatmap(confusion, annot=True, fmt='d', cmap='Blues', ax=ax1,\n",
    "            xticklabels=['Negative', 'Positive'],\n",
    "            yticklabels=['No Disease', 'Disease'])\n",
    "ax1.set_title('Confusion Matrix')\n",
    "ax1.set_xlabel('Test Result')\n",
    "ax1.set_ylabel('True Status')\n",
    "\n",
    "# Probability tree\n",
    "ax2.text(0.5, 0.9, 'Population', ha='center', fontsize=12, weight='bold')\n",
    "ax2.plot([0.5, 0.2], [0.85, 0.6], 'k-')\n",
    "ax2.plot([0.5, 0.8], [0.85, 0.6], 'k-')\n",
    "ax2.text(0.2, 0.6, f'Disease\\n{p_disease:.1%}', ha='center', bbox=dict(boxstyle='round', facecolor='red', alpha=0.3))\n",
    "ax2.text(0.8, 0.6, f'No Disease\\n{p_no_disease:.1%}', ha='center', bbox=dict(boxstyle='round', facecolor='green', alpha=0.3))\n",
    "ax2.text(0.1, 0.3, f'Test+\\n{p_positive_given_disease:.0%}', ha='center')\n",
    "ax2.text(0.3, 0.3, f'Test-\\n{1-p_positive_given_disease:.0%}', ha='center')\n",
    "ax2.text(0.7, 0.3, f'Test+\\n{p_positive_given_no_disease:.0%}', ha='center')\n",
    "ax2.text(0.9, 0.3, f'Test-\\n{p_negative_given_no_disease:.0%}', ha='center')\n",
    "ax2.set_xlim(0, 1)\n",
    "ax2.set_ylim(0, 1)\n",
    "ax2.axis('off')\n",
    "ax2.set_title('Probability Tree')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìå Section 3: Probability Distributions\n",
    "\n",
    "### üéØ Patterns in Random Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.1 Common Distributions\n",
    "print(\"üìä PROBABILITY DISTRIBUTIONS\\n\" + \"=\"*40)\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "np.random.seed(42)\n",
    "\n",
    "# 1. Normal Distribution\n",
    "ax = axes[0, 0]\n",
    "x = np.linspace(-4, 4, 100)\n",
    "ax.plot(x, norm.pdf(x, 0, 1), 'b-', linewidth=2, label='Œº=0, œÉ=1')\n",
    "ax.plot(x, norm.pdf(x, 0, 2), 'r-', linewidth=2, label='Œº=0, œÉ=2')\n",
    "ax.plot(x, norm.pdf(x, 2, 1), 'g-', linewidth=2, label='Œº=2, œÉ=1')\n",
    "ax.set_title('Normal Distribution')\n",
    "ax.legend()\n",
    "ax.grid(True)\n",
    "\n",
    "# 2. Binomial Distribution\n",
    "ax = axes[0, 1]\n",
    "n, p = 20, 0.5\n",
    "x = np.arange(0, n+1)\n",
    "ax.bar(x, stats.binom.pmf(x, n, p), alpha=0.7)\n",
    "ax.set_title(f'Binomial Distribution (n={n}, p={p})')\n",
    "ax.set_xlabel('Number of Successes')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Poisson Distribution\n",
    "ax = axes[0, 2]\n",
    "lambdas = [1, 4, 7]\n",
    "x = np.arange(0, 15)\n",
    "for lam in lambdas:\n",
    "    ax.plot(x, stats.poisson.pmf(x, lam), marker='o', label=f'Œª={lam}')\n",
    "ax.set_title('Poisson Distribution')\n",
    "ax.set_xlabel('Number of Events')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Exponential Distribution\n",
    "ax = axes[1, 0]\n",
    "x = np.linspace(0, 5, 100)\n",
    "for scale in [0.5, 1, 2]:\n",
    "    ax.plot(x, stats.expon.pdf(x, scale=scale), linewidth=2, label=f'Œª={1/scale:.1f}')\n",
    "ax.set_title('Exponential Distribution')\n",
    "ax.set_xlabel('Time')\n",
    "ax.legend()\n",
    "ax.grid(True)\n",
    "\n",
    "# 5. Uniform Distribution\n",
    "ax = axes[1, 1]\n",
    "x = np.linspace(-1, 5, 1000)\n",
    "ax.plot(x, stats.uniform.pdf(x, 0, 1), linewidth=2, label='[0, 1]')\n",
    "ax.plot(x, stats.uniform.pdf(x, 1, 2), linewidth=2, label='[1, 3]')\n",
    "ax.set_title('Uniform Distribution')\n",
    "ax.legend()\n",
    "ax.grid(True)\n",
    "ax.set_ylim(0, 1.2)\n",
    "\n",
    "# 6. Chi-Square Distribution\n",
    "ax = axes[1, 2]\n",
    "x = np.linspace(0, 20, 100)\n",
    "for df in [1, 3, 5, 9]:\n",
    "    ax.plot(x, stats.chi2.pdf(x, df), linewidth=2, label=f'df={df}')\n",
    "ax.set_title('Chi-Square Distribution')\n",
    "ax.set_xlabel('œá¬≤')\n",
    "ax.legend()\n",
    "ax.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüí° Key Applications:\")\n",
    "print(\"‚Ä¢ Normal: Heights, test scores, measurement errors\")\n",
    "print(\"‚Ä¢ Binomial: Success/failure experiments\")\n",
    "print(\"‚Ä¢ Poisson: Count of events in fixed time\")\n",
    "print(\"‚Ä¢ Exponential: Time between events\")\n",
    "print(\"‚Ä¢ Uniform: Random sampling\")\n",
    "print(\"‚Ä¢ Chi-Square: Goodness of fit tests\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.2 Central Limit Theorem\n",
    "print(\"üéØ CENTRAL LIMIT THEOREM\\n\" + \"=\"*40)\n",
    "\n",
    "# Demonstrate CLT with different distributions\n",
    "np.random.seed(42)\n",
    "n_samples = 1000\n",
    "sample_sizes = [1, 5, 30, 100]\n",
    "\n",
    "fig, axes = plt.subplots(3, 4, figsize=(15, 10))\n",
    "\n",
    "# Different source distributions\n",
    "distributions = [\n",
    "    ('Uniform', lambda: np.random.uniform(0, 1, n_samples)),\n",
    "    ('Exponential', lambda: np.random.exponential(1, n_samples)),\n",
    "    ('Bimodal', lambda: np.concatenate([np.random.normal(-2, 0.5, n_samples//2),\n",
    "                                        np.random.normal(2, 0.5, n_samples//2)]))\n",
    "]\n",
    "\n",
    "for row, (dist_name, dist_func) in enumerate(distributions):\n",
    "    for col, n in enumerate(sample_sizes):\n",
    "        ax = axes[row, col]\n",
    "        \n",
    "        # Generate sample means\n",
    "        sample_means = []\n",
    "        for _ in range(1000):\n",
    "            sample = dist_func()[:n]\n",
    "            sample_means.append(np.mean(sample))\n",
    "        \n",
    "        # Plot histogram\n",
    "        ax.hist(sample_means, bins=30, density=True, alpha=0.7, edgecolor='black')\n",
    "        \n",
    "        # Overlay normal distribution\n",
    "        mu = np.mean(sample_means)\n",
    "        sigma = np.std(sample_means)\n",
    "        x = np.linspace(mu - 4*sigma, mu + 4*sigma, 100)\n",
    "        ax.plot(x, norm.pdf(x, mu, sigma), 'r-', linewidth=2)\n",
    "        \n",
    "        ax.set_title(f'{dist_name} (n={n})')\n",
    "        if col == 0:\n",
    "            ax.set_ylabel('Density')\n",
    "        if row == 2:\n",
    "            ax.set_xlabel('Sample Mean')\n",
    "\n",
    "plt.suptitle('Central Limit Theorem: Sample Means Become Normal', fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüí° Key Insight:\")\n",
    "print(\"No matter the original distribution, sample means become normally distributed!\")\n",
    "print(\"This is why the normal distribution is so important in statistics.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìå Section 4: Hypothesis Testing\n",
    "\n",
    "### üéØ Making Scientific Decisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.1 Hypothesis Testing Framework\n",
    "print(\"üî¨ HYPOTHESIS TESTING\\n\" + \"=\"*40)\n",
    "\n",
    "# A/B Testing Example: Website Conversion Rates\n",
    "np.random.seed(42)\n",
    "\n",
    "# Simulate data\n",
    "n_visitors_A = 1000\n",
    "n_visitors_B = 1000\n",
    "conversion_rate_A = 0.10  # 10% conversion\n",
    "conversion_rate_B = 0.12  # 12% conversion (we want to detect this)\n",
    "\n",
    "# Generate conversions\n",
    "conversions_A = np.random.binomial(n_visitors_A, conversion_rate_A)\n",
    "conversions_B = np.random.binomial(n_visitors_B, conversion_rate_B)\n",
    "\n",
    "# Calculate observed rates\n",
    "p_A = conversions_A / n_visitors_A\n",
    "p_B = conversions_B / n_visitors_B\n",
    "\n",
    "print(\"A/B Test Results:\")\n",
    "print(f\"Version A: {conversions_A}/{n_visitors_A} = {p_A:.1%} conversion\")\n",
    "print(f\"Version B: {conversions_B}/{n_visitors_B} = {p_B:.1%} conversion\")\n",
    "print(f\"Difference: {(p_B - p_A)*100:.1f} percentage points\")\n",
    "\n",
    "# Two-proportion z-test\n",
    "pooled_p = (conversions_A + conversions_B) / (n_visitors_A + n_visitors_B)\n",
    "se = np.sqrt(pooled_p * (1 - pooled_p) * (1/n_visitors_A + 1/n_visitors_B))\n",
    "z_stat = (p_B - p_A) / se\n",
    "p_value = 2 * (1 - norm.cdf(abs(z_stat)))\n",
    "\n",
    "print(f\"\\nStatistical Test:\")\n",
    "print(f\"Z-statistic: {z_stat:.3f}\")\n",
    "print(f\"P-value: {p_value:.4f}\")\n",
    "\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(f\"Result: SIGNIFICANT (p < {alpha})\")\n",
    "    print(\"‚Üí Reject null hypothesis: Version B is better!\")\n",
    "else:\n",
    "    print(f\"Result: NOT SIGNIFICANT (p >= {alpha})\")\n",
    "    print(\"‚Üí Cannot conclude Version B is better\")\n",
    "\n",
    "# Visualize\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Conversion rates with confidence intervals\n",
    "versions = ['A', 'B']\n",
    "rates = [p_A, p_B]\n",
    "errors = [1.96 * np.sqrt(p_A*(1-p_A)/n_visitors_A),\n",
    "          1.96 * np.sqrt(p_B*(1-p_B)/n_visitors_B)]\n",
    "\n",
    "ax1.bar(versions, rates, yerr=errors, capsize=10, alpha=0.7)\n",
    "ax1.set_ylabel('Conversion Rate')\n",
    "ax1.set_title('A/B Test Results with 95% Confidence Intervals')\n",
    "ax1.set_ylim(0, 0.15)\n",
    "\n",
    "# Null distribution and test statistic\n",
    "x = np.linspace(-4, 4, 100)\n",
    "ax2.plot(x, norm.pdf(x), 'b-', linewidth=2, label='Null Distribution')\n",
    "ax2.axvline(z_stat, color='red', linestyle='--', linewidth=2, label=f'Observed Z={z_stat:.2f}')\n",
    "ax2.axvline(-1.96, color='gray', linestyle=':', alpha=0.5)\n",
    "ax2.axvline(1.96, color='gray', linestyle=':', alpha=0.5)\n",
    "ax2.fill_between(x[x < -1.96], 0, norm.pdf(x[x < -1.96]), alpha=0.3, color='red')\n",
    "ax2.fill_between(x[x > 1.96], 0, norm.pdf(x[x > 1.96]), alpha=0.3, color='red')\n",
    "ax2.set_xlabel('Z-statistic')\n",
    "ax2.set_ylabel('Probability Density')\n",
    "ax2.set_title('Hypothesis Test Visualization')\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.2 Types of Statistical Tests\n",
    "print(\"üìã COMMON STATISTICAL TESTS\\n\" + \"=\"*40)\n",
    "\n",
    "# Generate sample datasets\n",
    "np.random.seed(42)\n",
    "\n",
    "# 1. One-sample t-test\n",
    "print(\"1Ô∏è‚É£ One-Sample T-Test\")\n",
    "print(\"Question: Is average different from expected value?\")\n",
    "sample = np.random.normal(100, 15, 30)  # IQ scores\n",
    "t_stat, p_val = stats.ttest_1samp(sample, 100)\n",
    "print(f\"Sample mean: {np.mean(sample):.2f}\")\n",
    "print(f\"Test against: 100\")\n",
    "print(f\"t-statistic: {t_stat:.3f}, p-value: {p_val:.4f}\")\n",
    "print()\n",
    "\n",
    "# 2. Two-sample t-test\n",
    "print(\"2Ô∏è‚É£ Two-Sample T-Test\")\n",
    "print(\"Question: Are two group means different?\")\n",
    "group1 = np.random.normal(100, 15, 50)\n",
    "group2 = np.random.normal(105, 15, 50)\n",
    "t_stat, p_val = stats.ttest_ind(group1, group2)\n",
    "print(f\"Group 1 mean: {np.mean(group1):.2f}\")\n",
    "print(f\"Group 2 mean: {np.mean(group2):.2f}\")\n",
    "print(f\"t-statistic: {t_stat:.3f}, p-value: {p_val:.4f}\")\n",
    "print()\n",
    "\n",
    "# 3. Paired t-test\n",
    "print(\"3Ô∏è‚É£ Paired T-Test\")\n",
    "print(\"Question: Is there a difference before/after treatment?\")\n",
    "before = np.random.normal(120, 10, 30)  # Blood pressure before\n",
    "after = before - np.random.normal(5, 3, 30)  # After treatment\n",
    "t_stat, p_val = stats.ttest_rel(before, after)\n",
    "print(f\"Mean before: {np.mean(before):.2f}\")\n",
    "print(f\"Mean after: {np.mean(after):.2f}\")\n",
    "print(f\"t-statistic: {t_stat:.3f}, p-value: {p_val:.4f}\")\n",
    "print()\n",
    "\n",
    "# 4. Chi-square test\n",
    "print(\"4Ô∏è‚É£ Chi-Square Test\")\n",
    "print(\"Question: Are categorical variables independent?\")\n",
    "# Create contingency table\n",
    "observed = np.array([[20, 30], [25, 25]])\n",
    "chi2_stat, p_val, dof, expected = stats.chi2_contingency(observed)\n",
    "print(\"Contingency Table:\")\n",
    "print(observed)\n",
    "print(f\"Chi-square: {chi2_stat:.3f}, p-value: {p_val:.4f}\")\n",
    "print()\n",
    "\n",
    "# 5. ANOVA\n",
    "print(\"5Ô∏è‚É£ ANOVA (Analysis of Variance)\")\n",
    "print(\"Question: Are means different across multiple groups?\")\n",
    "group_A = np.random.normal(100, 10, 30)\n",
    "group_B = np.random.normal(105, 10, 30)\n",
    "group_C = np.random.normal(110, 10, 30)\n",
    "f_stat, p_val = stats.f_oneway(group_A, group_B, group_C)\n",
    "print(f\"Group A mean: {np.mean(group_A):.2f}\")\n",
    "print(f\"Group B mean: {np.mean(group_B):.2f}\")\n",
    "print(f\"Group C mean: {np.mean(group_C):.2f}\")\n",
    "print(f\"F-statistic: {f_stat:.3f}, p-value: {p_val:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìå Section 5: Correlation and Regression\n",
    "\n",
    "### üéØ Finding Relationships in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.1 Correlation Analysis\n",
    "print(\"üîó CORRELATION ANALYSIS\\n\" + \"=\"*40)\n",
    "\n",
    "# Generate correlated data\n",
    "np.random.seed(42)\n",
    "n = 100\n",
    "\n",
    "# Different correlation patterns\n",
    "x = np.random.randn(n)\n",
    "\n",
    "# Strong positive correlation\n",
    "y_pos = 2 * x + np.random.randn(n) * 0.5\n",
    "\n",
    "# Strong negative correlation\n",
    "y_neg = -2 * x + np.random.randn(n) * 0.5\n",
    "\n",
    "# No correlation\n",
    "y_none = np.random.randn(n)\n",
    "\n",
    "# Non-linear relationship\n",
    "y_nonlinear = x**2 + np.random.randn(n) * 0.5\n",
    "\n",
    "# Calculate correlations\n",
    "correlations = [\n",
    "    ('Positive', x, y_pos, np.corrcoef(x, y_pos)[0, 1]),\n",
    "    ('Negative', x, y_neg, np.corrcoef(x, y_neg)[0, 1]),\n",
    "    ('None', x, y_none, np.corrcoef(x, y_none)[0, 1]),\n",
    "    ('Non-linear', x, y_nonlinear, np.corrcoef(x, y_nonlinear)[0, 1])\n",
    "]\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i, (title, x_data, y_data, corr) in enumerate(correlations):\n",
    "    ax = axes[i]\n",
    "    ax.scatter(x_data, y_data, alpha=0.6)\n",
    "    ax.set_title(f'{title} Correlation (r = {corr:.3f})')\n",
    "    ax.set_xlabel('X')\n",
    "    ax.set_ylabel('Y')\n",
    "    \n",
    "    # Add regression line for linear relationships\n",
    "    if i < 3:\n",
    "        z = np.polyfit(x_data, y_data, 1)\n",
    "        p = np.poly1d(z)\n",
    "        ax.plot(sorted(x_data), p(sorted(x_data)), 'r-', linewidth=2)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüí° Important Notes:\")\n",
    "print(\"‚Ä¢ Correlation measures LINEAR relationships only\")\n",
    "print(\"‚Ä¢ Correlation ‚â† Causation\")\n",
    "print(\"‚Ä¢ Always visualize your data!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.2 Linear Regression Analysis\n",
    "print(\"üìà LINEAR REGRESSION ANALYSIS\\n\" + \"=\"*40)\n",
    "\n",
    "# Generate data: House prices\n",
    "np.random.seed(42)\n",
    "n = 100\n",
    "size = np.random.uniform(1000, 3000, n)  # Square feet\n",
    "price = 100 + 0.15 * size + np.random.normal(0, 30, n)  # Price in $1000s\n",
    "\n",
    "# Perform regression\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(size, price)\n",
    "\n",
    "print(\"Regression Results:\")\n",
    "print(f\"Equation: Price = {intercept:.2f} + {slope:.4f} √ó Size\")\n",
    "print(f\"R-squared: {r_value**2:.3f}\")\n",
    "print(f\"P-value: {p_value:.4e}\")\n",
    "print(f\"Standard error: {std_err:.4f}\")\n",
    "\n",
    "# Predictions\n",
    "line = slope * size + intercept\n",
    "residuals = price - line\n",
    "\n",
    "# Confidence intervals\n",
    "confidence = 0.95\n",
    "predict_std = np.sqrt(np.mean(residuals**2))\n",
    "margin = 1.96 * predict_std\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "# Scatter plot with regression line\n",
    "ax = axes[0, 0]\n",
    "ax.scatter(size, price, alpha=0.6)\n",
    "ax.plot(size, line, 'r-', linewidth=2, label='Regression Line')\n",
    "ax.fill_between(sorted(size), sorted(line - margin), sorted(line + margin), \n",
    "                alpha=0.2, color='red', label='95% Confidence')\n",
    "ax.set_xlabel('Size (sq ft)')\n",
    "ax.set_ylabel('Price ($1000s)')\n",
    "ax.set_title('House Price vs Size')\n",
    "ax.legend()\n",
    "\n",
    "# Residual plot\n",
    "ax = axes[0, 1]\n",
    "ax.scatter(line, residuals, alpha=0.6)\n",
    "ax.axhline(y=0, color='red', linestyle='--')\n",
    "ax.set_xlabel('Fitted Values')\n",
    "ax.set_ylabel('Residuals')\n",
    "ax.set_title('Residual Plot')\n",
    "\n",
    "# Q-Q plot of residuals\n",
    "ax = axes[1, 0]\n",
    "stats.probplot(residuals, dist=\"norm\", plot=ax)\n",
    "ax.set_title('Q-Q Plot of Residuals')\n",
    "\n",
    "# Histogram of residuals\n",
    "ax = axes[1, 1]\n",
    "ax.hist(residuals, bins=20, edgecolor='black', alpha=0.7)\n",
    "ax.set_xlabel('Residuals')\n",
    "ax.set_ylabel('Frequency')\n",
    "ax.set_title('Distribution of Residuals')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüí° Interpretation:\")\n",
    "print(f\"‚Ä¢ Each additional sq ft increases price by ${slope*1000:.0f}\")\n",
    "print(f\"‚Ä¢ Model explains {r_value**2*100:.1f}% of price variation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìå Section 6: Confidence Intervals\n",
    "\n",
    "### üéØ Quantifying Uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.1 Understanding Confidence Intervals\n",
    "print(\"üìä CONFIDENCE INTERVALS\\n\" + \"=\"*40)\n",
    "\n",
    "# Simulate sampling from population\n",
    "np.random.seed(42)\n",
    "population_mean = 100\n",
    "population_std = 15\n",
    "\n",
    "# Take multiple samples\n",
    "n_samples = 100\n",
    "sample_size = 30\n",
    "confidence_level = 0.95\n",
    "\n",
    "sample_means = []\n",
    "confidence_intervals = []\n",
    "\n",
    "for _ in range(n_samples):\n",
    "    sample = np.random.normal(population_mean, population_std, sample_size)\n",
    "    sample_mean = np.mean(sample)\n",
    "    sample_std = np.std(sample, ddof=1)\n",
    "    \n",
    "    # Calculate confidence interval\n",
    "    margin_error = stats.t.ppf((1 + confidence_level) / 2, sample_size - 1) * (sample_std / np.sqrt(sample_size))\n",
    "    ci_lower = sample_mean - margin_error\n",
    "    ci_upper = sample_mean + margin_error\n",
    "    \n",
    "    sample_means.append(sample_mean)\n",
    "    confidence_intervals.append((ci_lower, ci_upper))\n",
    "\n",
    "# Check how many contain true mean\n",
    "contains_true = sum(1 for ci in confidence_intervals if ci[0] <= population_mean <= ci[1])\n",
    "\n",
    "print(f\"Population mean: {population_mean}\")\n",
    "print(f\"Confidence level: {confidence_level*100:.0f}%\")\n",
    "print(f\"Intervals containing true mean: {contains_true}/{n_samples} = {contains_true}%\")\n",
    "\n",
    "# Visualize\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Plot first 20 confidence intervals\n",
    "for i in range(20):\n",
    "    ci = confidence_intervals[i]\n",
    "    color = 'green' if ci[0] <= population_mean <= ci[1] else 'red'\n",
    "    ax1.plot([ci[0], ci[1]], [i, i], color=color, linewidth=2)\n",
    "    ax1.plot(sample_means[i], i, 'ko', markersize=5)\n",
    "\n",
    "ax1.axvline(population_mean, color='blue', linestyle='--', linewidth=2, label='True Mean')\n",
    "ax1.set_ylabel('Sample Number')\n",
    "ax1.set_xlabel('Value')\n",
    "ax1.set_title('95% Confidence Intervals (First 20 Samples)')\n",
    "ax1.legend()\n",
    "\n",
    "# Effect of sample size on CI width\n",
    "sample_sizes = [10, 30, 50, 100, 200, 500]\n",
    "ci_widths = []\n",
    "\n",
    "for n in sample_sizes:\n",
    "    sample = np.random.normal(population_mean, population_std, n)\n",
    "    sample_std = np.std(sample, ddof=1)\n",
    "    margin = stats.t.ppf(0.975, n-1) * (sample_std / np.sqrt(n))\n",
    "    ci_widths.append(2 * margin)\n",
    "\n",
    "ax2.plot(sample_sizes, ci_widths, 'bo-', linewidth=2, markersize=8)\n",
    "ax2.set_xlabel('Sample Size')\n",
    "ax2.set_ylabel('CI Width')\n",
    "ax2.set_title('Confidence Interval Width vs Sample Size')\n",
    "ax2.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüí° Key Insights:\")\n",
    "print(\"‚Ä¢ 95% CI means: If we repeat sampling many times,\")\n",
    "print(\"  95% of intervals will contain the true value\")\n",
    "print(\"‚Ä¢ Larger samples ‚Üí Narrower intervals\")\n",
    "print(\"‚Ä¢ CI is about the parameter, not individual observations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìå Section 7: Power Analysis and Sample Size\n",
    "\n",
    "### üéØ Planning Your Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.1 Statistical Power and Sample Size\n",
    "print(\"‚ö° STATISTICAL POWER ANALYSIS\\n\" + \"=\"*40)\n",
    "\n",
    "from statsmodels.stats.power import TTestPower\n",
    "\n",
    "# Power analysis for t-test\n",
    "power_analysis = TTestPower()\n",
    "\n",
    "# Effect sizes: Small (0.2), Medium (0.5), Large (0.8)\n",
    "effect_sizes = [0.2, 0.5, 0.8]\n",
    "alpha = 0.05\n",
    "power = 0.8\n",
    "\n",
    "print(\"Required Sample Sizes for 80% Power:\")\n",
    "print(\"-\" * 40)\n",
    "for effect_size in effect_sizes:\n",
    "    n = power_analysis.solve_power(effect_size=effect_size, power=power, alpha=alpha)\n",
    "    print(f\"Effect Size {effect_size}: n = {n:.0f} per group\")\n",
    "\n",
    "# Visualize power curves\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Power vs Sample Size\n",
    "sample_sizes = np.arange(10, 200, 5)\n",
    "for effect_size in effect_sizes:\n",
    "    powers = [power_analysis.calc_power(effect_size=effect_size, nobs=n, alpha=alpha) \n",
    "              for n in sample_sizes]\n",
    "    ax1.plot(sample_sizes, powers, linewidth=2, label=f'Effect={effect_size}')\n",
    "\n",
    "ax1.axhline(y=0.8, color='red', linestyle='--', alpha=0.5, label='80% Power')\n",
    "ax1.set_xlabel('Sample Size (per group)')\n",
    "ax1.set_ylabel('Statistical Power')\n",
    "ax1.set_title('Power Curves')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Type I and Type II Errors\n",
    "x = np.linspace(-4, 8, 1000)\n",
    "null_dist = norm.pdf(x, 0, 1)\n",
    "alt_dist = norm.pdf(x, 2, 1)\n",
    "\n",
    "ax2.plot(x, null_dist, 'b-', linewidth=2, label='Null (H‚ÇÄ)')\n",
    "ax2.plot(x, alt_dist, 'r-', linewidth=2, label='Alternative (H‚ÇÅ)')\n",
    "\n",
    "# Critical value\n",
    "crit_val = norm.ppf(1 - alpha)\n",
    "ax2.axvline(crit_val, color='black', linestyle='--', label='Critical Value')\n",
    "\n",
    "# Shade regions\n",
    "ax2.fill_between(x[x > crit_val], 0, null_dist[x > crit_val], \n",
    "                 alpha=0.3, color='blue', label='Type I Error (Œ±)')\n",
    "ax2.fill_between(x[x < crit_val], 0, alt_dist[x < crit_val], \n",
    "                 alpha=0.3, color='red', label='Type II Error (Œ≤)')\n",
    "\n",
    "ax2.set_xlabel('Test Statistic')\n",
    "ax2.set_ylabel('Probability Density')\n",
    "ax2.set_title('Type I and Type II Errors')\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüí° Key Concepts:\")\n",
    "print(\"‚Ä¢ Power = Probability of detecting a true effect\")\n",
    "print(\"‚Ä¢ Type I Error (Œ±) = False positive\")\n",
    "print(\"‚Ä¢ Type II Error (Œ≤) = False negative\")\n",
    "print(\"‚Ä¢ Power = 1 - Œ≤\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìå Section 8: Bayesian Statistics\n",
    "\n",
    "### üéØ Updating Beliefs with Evidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8.1 Bayesian Updating\n",
    "print(\"üîÑ BAYESIAN STATISTICS\\n\" + \"=\"*40)\n",
    "\n",
    "# Coin flip example: Is the coin fair?\n",
    "# Prior belief: Uniform (any bias equally likely)\n",
    "# Data: Observe coin flips\n",
    "\n",
    "# Prior\n",
    "theta_range = np.linspace(0, 1, 100)\n",
    "prior = np.ones_like(theta_range)  # Uniform prior\n",
    "prior = prior / np.sum(prior)\n",
    "\n",
    "# Simulate coin flips\n",
    "np.random.seed(42)\n",
    "true_bias = 0.7  # Actual bias (unknown to us)\n",
    "n_flips = [0, 1, 5, 10, 50, 100]\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i, n in enumerate(n_flips):\n",
    "    ax = axes[i]\n",
    "    \n",
    "    if n == 0:\n",
    "        posterior = prior\n",
    "        heads = 0\n",
    "    else:\n",
    "        # Generate data\n",
    "        flips = np.random.random(n) < true_bias\n",
    "        heads = np.sum(flips)\n",
    "        \n",
    "        # Calculate likelihood\n",
    "        likelihood = theta_range**heads * (1-theta_range)**(n-heads)\n",
    "        \n",
    "        # Calculate posterior\n",
    "        posterior = prior * likelihood\n",
    "        posterior = posterior / np.sum(posterior)\n",
    "    \n",
    "    # Plot\n",
    "    ax.plot(theta_range, posterior, linewidth=2)\n",
    "    ax.axvline(true_bias, color='red', linestyle='--', alpha=0.5, label='True Value')\n",
    "    if n > 0:\n",
    "        ax.axvline(heads/n, color='green', linestyle='--', alpha=0.5, label='Observed')\n",
    "    \n",
    "    ax.set_xlabel('Coin Bias (P(Heads))')\n",
    "    ax.set_ylabel('Probability')\n",
    "    ax.set_title(f'After {n} flips ({heads} heads)' if n > 0 else 'Prior Belief')\n",
    "    ax.legend()\n",
    "    \n",
    "    # Update prior for next iteration\n",
    "    if n > 0:\n",
    "        prior = posterior\n",
    "\n",
    "plt.suptitle('Bayesian Learning: Updating Beliefs with Data', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüí° Bayesian vs Frequentist:\")\n",
    "print(\"‚Ä¢ Bayesian: Probability = Degree of belief\")\n",
    "print(\"‚Ä¢ Frequentist: Probability = Long-run frequency\")\n",
    "print(\"‚Ä¢ Bayesian explicitly incorporates prior knowledge\")\n",
    "print(\"‚Ä¢ Posterior becomes more concentrated with more data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìå Section 9: Time Series Basics\n",
    "\n",
    "### üéØ Analyzing Data Over Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9.1 Time Series Analysis\n",
    "print(\"üìà TIME SERIES ANALYSIS\\n\" + \"=\"*40)\n",
    "\n",
    "# Generate time series data\n",
    "np.random.seed(42)\n",
    "n_points = 365\n",
    "time = np.arange(n_points)\n",
    "\n",
    "# Components\n",
    "trend = 100 + 0.1 * time\n",
    "seasonal = 10 * np.sin(2 * np.pi * time / 30)  # Monthly pattern\n",
    "noise = np.random.normal(0, 5, n_points)\n",
    "series = trend + seasonal + noise\n",
    "\n",
    "# Calculate moving average\n",
    "window = 30\n",
    "moving_avg = pd.Series(series).rolling(window=window).mean()\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(3, 1, figsize=(12, 10))\n",
    "\n",
    "# Original series\n",
    "ax = axes[0]\n",
    "ax.plot(time, series, alpha=0.5, label='Original')\n",
    "ax.plot(time, moving_avg, 'r-', linewidth=2, label=f'{window}-day Moving Average')\n",
    "ax.set_ylabel('Value')\n",
    "ax.set_title('Time Series with Moving Average')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Decomposition\n",
    "ax = axes[1]\n",
    "ax.plot(time, trend, label='Trend', linewidth=2)\n",
    "ax.plot(time, trend + seasonal, label='Trend + Seasonal', alpha=0.7)\n",
    "ax.set_ylabel('Value')\n",
    "ax.set_title('Time Series Components')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Autocorrelation\n",
    "ax = axes[2]\n",
    "lags = range(60)\n",
    "acf = [pd.Series(series).autocorr(lag) for lag in lags]\n",
    "ax.bar(lags, acf, alpha=0.7)\n",
    "ax.axhline(y=0, color='black', linewidth=0.5)\n",
    "ax.set_xlabel('Lag')\n",
    "ax.set_ylabel('Autocorrelation')\n",
    "ax.set_title('Autocorrelation Function')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüí° Time Series Components:\")\n",
    "print(\"‚Ä¢ Trend: Long-term direction\")\n",
    "print(\"‚Ä¢ Seasonality: Repeating patterns\")\n",
    "print(\"‚Ä¢ Noise: Random fluctuations\")\n",
    "print(\"‚Ä¢ Autocorrelation: Correlation with past values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéØ Section 10: Real Business Applications\n",
    "\n",
    "### Putting It All Together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10.1 Complete Business Analysis\n",
    "print(\"üíº BUSINESS CASE: CUSTOMER CHURN ANALYSIS\\n\" + \"=\"*50)\n",
    "\n",
    "# Generate customer data\n",
    "np.random.seed(42)\n",
    "n_customers = 1000\n",
    "\n",
    "# Features\n",
    "tenure = np.random.uniform(0, 60, n_customers)  # Months\n",
    "monthly_charges = np.random.uniform(20, 100, n_customers)\n",
    "total_charges = tenure * monthly_charges + np.random.normal(0, 100, n_customers)\n",
    "support_calls = np.random.poisson(2, n_customers)\n",
    "\n",
    "# Churn probability based on features\n",
    "churn_prob = 1 / (1 + np.exp(-(-2 + 0.02*tenure - 0.01*monthly_charges + 0.3*support_calls)))\n",
    "churned = np.random.random(n_customers) < churn_prob\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'tenure': tenure,\n",
    "    'monthly_charges': monthly_charges,\n",
    "    'total_charges': total_charges,\n",
    "    'support_calls': support_calls,\n",
    "    'churned': churned\n",
    "})\n",
    "\n",
    "print(\"üìä Dataset Overview:\")\n",
    "print(df.describe())\n",
    "print(f\"\\nChurn Rate: {df['churned'].mean()*100:.1f}%\")\n",
    "\n",
    "# Statistical Analysis\n",
    "print(\"\\nüìà Statistical Tests:\")\n",
    "\n",
    "# T-test: Tenure difference\n",
    "churned_tenure = df[df['churned']]['tenure']\n",
    "retained_tenure = df[~df['churned']]['tenure']\n",
    "t_stat, p_val = stats.ttest_ind(churned_tenure, retained_tenure)\n",
    "print(f\"\\nTenure Comparison:\")\n",
    "print(f\"Churned: {churned_tenure.mean():.1f} months\")\n",
    "print(f\"Retained: {retained_tenure.mean():.1f} months\")\n",
    "print(f\"T-test p-value: {p_val:.4f}\")\n",
    "\n",
    "# Correlation analysis\n",
    "print(\"\\nüîó Correlation with Churn:\")\n",
    "for col in ['tenure', 'monthly_charges', 'support_calls']:\n",
    "    corr = df[col].corr(df['churned'].astype(int))\n",
    "    print(f\"{col}: {corr:.3f}\")\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "# Churn by tenure\n",
    "ax = axes[0, 0]\n",
    "df.boxplot(column='tenure', by='churned', ax=ax)\n",
    "ax.set_title('Tenure by Churn Status')\n",
    "ax.set_xlabel('Churned')\n",
    "ax.set_ylabel('Tenure (months)')\n",
    "plt.sca(ax)\n",
    "plt.xticks([1, 2], ['No', 'Yes'])\n",
    "\n",
    "# Churn by support calls\n",
    "ax = axes[0, 1]\n",
    "churn_by_calls = df.groupby('support_calls')['churned'].mean()\n",
    "ax.bar(churn_by_calls.index, churn_by_calls.values, alpha=0.7)\n",
    "ax.set_xlabel('Support Calls')\n",
    "ax.set_ylabel('Churn Rate')\n",
    "ax.set_title('Churn Rate by Support Calls')\n",
    "\n",
    "# Monthly charges distribution\n",
    "ax = axes[1, 0]\n",
    "ax.hist(df[df['churned']]['monthly_charges'], alpha=0.5, label='Churned', bins=20)\n",
    "ax.hist(df[~df['churned']]['monthly_charges'], alpha=0.5, label='Retained', bins=20)\n",
    "ax.set_xlabel('Monthly Charges ($)')\n",
    "ax.set_ylabel('Count')\n",
    "ax.set_title('Monthly Charges Distribution')\n",
    "ax.legend()\n",
    "\n",
    "# Survival curve\n",
    "ax = axes[1, 1]\n",
    "tenure_bins = np.arange(0, 61, 6)\n",
    "survival_rates = []\n",
    "for i in range(len(tenure_bins)-1):\n",
    "    mask = (df['tenure'] >= tenure_bins[i]) & (df['tenure'] < tenure_bins[i+1])\n",
    "    survival_rate = 1 - df[mask]['churned'].mean()\n",
    "    survival_rates.append(survival_rate)\n",
    "\n",
    "ax.plot(tenure_bins[:-1], survival_rates, 'bo-', linewidth=2, markersize=8)\n",
    "ax.set_xlabel('Tenure (months)')\n",
    "ax.set_ylabel('Retention Rate')\n",
    "ax.set_title('Customer Survival Curve')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüí° Business Insights:\")\n",
    "print(\"‚Ä¢ Longer tenure strongly associated with retention\")\n",
    "print(\"‚Ä¢ Support calls are a key churn indicator\")\n",
    "print(\"‚Ä¢ Focus retention efforts on new customers\")\n",
    "print(\"‚Ä¢ Improve customer support to reduce churn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéØ Summary & Next Steps\n",
    "\n",
    "### üèÜ What You've Learned:\n",
    "\n",
    "‚úÖ **Descriptive Statistics**\n",
    "- Central tendency and spread\n",
    "- Visualizing distributions\n",
    "- Understanding your data\n",
    "\n",
    "‚úÖ **Probability & Distributions**\n",
    "- Basic probability concepts\n",
    "- Common distributions\n",
    "- Central Limit Theorem\n",
    "\n",
    "‚úÖ **Inferential Statistics**\n",
    "- Hypothesis testing\n",
    "- Confidence intervals\n",
    "- Statistical power\n",
    "\n",
    "‚úÖ **Relationships in Data**\n",
    "- Correlation analysis\n",
    "- Linear regression\n",
    "- Time series basics\n",
    "\n",
    "‚úÖ **Applied Statistics**\n",
    "- A/B testing\n",
    "- Bayesian thinking\n",
    "- Business applications\n",
    "\n",
    "### üöÄ Next Steps:\n",
    "\n",
    "1. **Practice with Real Data** - Apply these techniques\n",
    "2. **Learn Data Preprocessing** - Next notebook!\n",
    "3. **Master EDA** - Exploratory Data Analysis\n",
    "4. **Apply to ML** - Statistics powers machine learning\n",
    "\n",
    "### üí° Key Takeaways:\n",
    "\n",
    "- **Statistics is about understanding uncertainty**\n",
    "- **Always visualize your data**\n",
    "- **Choose the right test for your question**\n",
    "- **Interpret results in business context**\n",
    "\n",
    "### üìö Resources:\n",
    "\n",
    "- Think Stats by Allen B. Downey\n",
    "- Statistics in Plain English\n",
    "- Khan Academy Statistics\n",
    "- StatQuest YouTube Channel\n",
    "\n",
    "---\n",
    "\n",
    "## üéâ Congratulations!\n",
    "\n",
    "You now understand the essential statistics for data science!\n",
    "\n",
    "Remember: **Statistics is the bridge between data and decisions.**\n",
    "\n",
    "**Keep exploring, keep questioning, keep learning!** üöÄ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üéä Chapter Complete!\n",
    "print(\"üéä\" * 20)\n",
    "print(\"\\n    üèÜ STATISTICS FOR DATA SCIENCE COMPLETE! üèÜ\")\n",
    "print(\"\\n    You've mastered:\")\n",
    "print(\"    ‚úÖ Descriptive Statistics\")\n",
    "print(\"    ‚úÖ Probability & Distributions\")\n",
    "print(\"    ‚úÖ Hypothesis Testing\")\n",
    "print(\"    ‚úÖ Regression & Correlation\")\n",
    "print(\"    ‚úÖ Business Applications\")\n",
    "print(\"\\n    Ready for: Data Preprocessing!\")\n",
    "print(\"\\n\" + \"üéä\" * 20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}