{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üêº Pandas Mastery: Data Analysis Superpower\n",
    "\n",
    "<img src='https://pandas.pydata.org/static/img/pandas_white.svg' width='400' alt='Pandas Logo' style='background-color: #130754; padding: 20px;'>\n",
    "\n",
    "## üìö Welcome to Data Analysis Heaven!\n",
    "\n",
    "**Pandas** is the Swiss Army knife of data analysis in Python. If NumPy is the engine, Pandas is the luxury car built on top of it!\n",
    "\n",
    "### üéØ Why Pandas Rules the Data World:\n",
    "- **DataFrames** - Think Excel on steroids! üí™\n",
    "- **Missing Data Handling** - Clean messy data like a pro\n",
    "- **Time Series** - Financial data analysis made easy\n",
    "- **Data Wrangling** - Merge, join, reshape with ease\n",
    "- **SQL-like Operations** - GROUP BY, JOIN, and more!\n",
    "- **File I/O** - Read/write CSV, Excel, JSON, SQL, and more\n",
    "\n",
    "### üìä What We'll Master Today:\n",
    "1. **Series & DataFrames** - The building blocks\n",
    "2. **Data Loading & Inspection** - Get your data in\n",
    "3. **Indexing & Selection** - Access any data point\n",
    "4. **Data Cleaning** - Handle missing/duplicate data\n",
    "5. **Data Transformation** - Apply, map, and more\n",
    "6. **Grouping & Aggregation** - SQL-like operations\n",
    "7. **Merging & Joining** - Combine datasets\n",
    "8. **Time Series Analysis** - Work with dates\n",
    "9. **Visualization** - Quick plots\n",
    "10. **Real-World Projects** - Apply everything!\n",
    "\n",
    "---\n",
    "\n",
    "## üöÄ Let's Begin Our Journey!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\RC\\miniconda3\\envs\\ML_Python\\Lib\\site-packages\\pandas\\core\\arrays\\masked.py:61: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üêº Pandas Version: 2.3.1\n",
      "\n",
      "‚úÖ Pandas loaded successfully! Let's analyze some data!\n"
     ]
    }
   ],
   "source": [
    "# Import the essentials\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Display settings for better visibility\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 10)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "print(f\"üêº Pandas Version: {pd.__version__}\")\n",
    "print(\"\\n‚úÖ Pandas loaded successfully! Let's analyze some data!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìå Section 1: Series & DataFrames - The Building Blocks\n",
    "\n",
    "### üîç Understanding Pandas Data Structures\n",
    "\n",
    "- **Series**: 1D labeled array (like a column in Excel)\n",
    "- **DataFrame**: 2D labeled table (like an Excel spreadsheet)\n",
    "\n",
    "<img src='https://miro.medium.com/max/1400/1*xfJGLLKJzJfzkRhLZE-anw.png' width='600' alt='Series vs DataFrame'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Creating Pandas Series\n",
      "========================================\n",
      "Simple Series:\n",
      "0    22\n",
      "1    24\n",
      "2    19\n",
      "3    23\n",
      "4    25\n",
      "5    18\n",
      "6    21\n",
      "dtype: int64\n",
      "\n",
      "Series with custom index:\n",
      "Mon    22\n",
      "Tue    24\n",
      "Wed    19\n",
      "Thu    23\n",
      "Fri    25\n",
      "Sat    18\n",
      "Sun    21\n",
      "Name: Temperature, dtype: int64\n",
      "\n",
      "Series from dictionary:\n",
      "iPhone     500\n",
      "Samsung    450\n",
      "Xiaomi     300\n",
      "OnePlus    150\n",
      "Name: Units Sold, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 1.1 Creating a Series\n",
    "print(\"üìä Creating Pandas Series\\n\" + \"=\"*40)\n",
    "\n",
    "# From a list\n",
    "temperatures = pd.Series([22, 24, 19, 23, 25, 18, 21])\n",
    "print(\"Simple Series:\")\n",
    "print(temperatures)\n",
    "\n",
    "# With custom index\n",
    "days = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']\n",
    "temp_series = pd.Series([22, 24, 19, 23, 25, 18, 21], index=days, name='Temperature')\n",
    "print(\"\\nSeries with custom index:\")\n",
    "print(temp_series)\n",
    "\n",
    "# From dictionary\n",
    "sales_dict = {'iPhone': 500, 'Samsung': 450, 'Xiaomi': 300, 'OnePlus': 150}\n",
    "sales_series = pd.Series(sales_dict, name='Units Sold')\n",
    "print(\"\\nSeries from dictionary:\")\n",
    "print(sales_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Creating DataFrames\n",
      "========================================\n",
      "DataFrame from dictionary:\n",
      "      Name  Age     City  Salary\n",
      "0    Alice   25      NYC   70000\n",
      "1      Bob   30       LA   85000\n",
      "2  Charlie   35  Chicago   95000\n",
      "3    David   28  Houston   65000\n",
      "4     Emma   32  Phoenix   78000\n",
      "\n",
      "DataFrame from list of dicts:\n",
      "    Product  Price  Quantity\n",
      "0    Laptop   1200         5\n",
      "1     Mouse     25        50\n",
      "2  Keyboard     75        30\n",
      "3   Monitor    300        10\n"
     ]
    }
   ],
   "source": [
    "# 1.2 Creating DataFrames\n",
    "print(\"üìä Creating DataFrames\\n\" + \"=\"*40)\n",
    "\n",
    "# Method 1: From dictionary\n",
    "data = {\n",
    "    'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Emma'],\n",
    "    'Age': [25, 30, 35, 28, 32],\n",
    "    'City': ['NYC', 'LA', 'Chicago', 'Houston', 'Phoenix'],\n",
    "    'Salary': [70000, 85000, 95000, 65000, 78000]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(\"DataFrame from dictionary:\")\n",
    "print(df)\n",
    "\n",
    "# Method 2: From list of dictionaries\n",
    "records = [\n",
    "    {'Product': 'Laptop', 'Price': 1200, 'Quantity': 5},\n",
    "    {'Product': 'Mouse', 'Price': 25, 'Quantity': 50},\n",
    "    {'Product': 'Keyboard', 'Price': 75, 'Quantity': 30},\n",
    "    {'Product': 'Monitor', 'Price': 300, 'Quantity': 10}\n",
    "]\n",
    "\n",
    "products_df = pd.DataFrame(records)\n",
    "print(\"\\nDataFrame from list of dicts:\")\n",
    "print(products_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ÑπÔ∏è DataFrame Information\n",
      "========================================\n",
      "DataFrame shape: (100, 5)\n",
      "\n",
      "Column names: ['A', 'B', 'C', 'D', 'E']\n",
      "\n",
      "Data types:\n",
      "A           float64\n",
      "B             int32\n",
      "C            object\n",
      "D    datetime64[ns]\n",
      "E           float64\n",
      "dtype: object\n",
      "\n",
      "Memory usage:\n",
      "Index    132\n",
      "A        800\n",
      "B        400\n",
      "C        800\n",
      "D        800\n",
      "E        800\n",
      "dtype: int64\n",
      "\n",
      "Basic info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 5 columns):\n",
      " #   Column  Non-Null Count  Dtype         \n",
      "---  ------  --------------  -----         \n",
      " 0   A       100 non-null    float64       \n",
      " 1   B       100 non-null    int32         \n",
      " 2   C       100 non-null    object        \n",
      " 3   D       100 non-null    datetime64[ns]\n",
      " 4   E       100 non-null    float64       \n",
      "dtypes: datetime64[ns](1), float64(2), int32(1), object(1)\n",
      "memory usage: 3.6+ KB\n"
     ]
    }
   ],
   "source": [
    "# 1.3 DataFrame Information\n",
    "print(\"‚ÑπÔ∏è DataFrame Information\\n\" + \"=\"*40)\n",
    "\n",
    "# Create a sample DataFrame\n",
    "np.random.seed(42)\n",
    "df = pd.DataFrame({\n",
    "    'A': np.random.randn(100),\n",
    "    'B': np.random.randint(0, 50, 100),\n",
    "    'C': np.random.choice(['X', 'Y', 'Z'], 100),\n",
    "    'D': pd.date_range('2024-01-01', periods=100),\n",
    "    'E': np.random.random(100) * 1000\n",
    "})\n",
    "\n",
    "print(\"DataFrame shape:\", df.shape)\n",
    "print(\"\\nColumn names:\", df.columns.tolist())\n",
    "print(\"\\nData types:\")\n",
    "print(df.dtypes)\n",
    "print(\"\\nMemory usage:\")\n",
    "print(df.memory_usage())\n",
    "print(\"\\nBasic info:\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üèãÔ∏è Exercise 1: Create Your First DataFrame\n",
    "\n",
    "Create a DataFrame containing information about 5 movies with columns:\n",
    "- Title, Year, Rating, Runtime (minutes), Revenue (millions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movies DataFrame:\n",
      "             Title  Year  Rating  Runtime  Revenue\n",
      "0        Inception  2010     8.8      148    836.8\n",
      "1       The Matrix  1999     8.7      136    467.2\n",
      "2     Interstellar  2014     8.6      169    677.5\n",
      "3  The Dark Knight  2008     9.0      152   1004.6\n",
      "4           Avatar  2009     7.8      162   2847.2\n",
      "\n",
      "Total revenue: $5833.3 million\n",
      "Average rating: 8.58\n"
     ]
    }
   ],
   "source": [
    "# Your solution here:\n",
    "\n",
    "# Solution:\n",
    "movies = pd.DataFrame({\n",
    "    'Title': ['Inception', 'The Matrix', 'Interstellar', 'The Dark Knight', 'Avatar'],\n",
    "    'Year': [2010, 1999, 2014, 2008, 2009],\n",
    "    'Rating': [8.8, 8.7, 8.6, 9.0, 7.8],\n",
    "    'Runtime': [148, 136, 169, 152, 162],\n",
    "    'Revenue': [836.8, 467.2, 677.5, 1004.6, 2847.2]\n",
    "})\n",
    "\n",
    "print(\"Movies DataFrame:\")\n",
    "print(movies)\n",
    "print(f\"\\nTotal revenue: ${movies['Revenue'].sum():.1f} million\")\n",
    "print(f\"Average rating: {movies['Rating'].mean():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìå Section 2: Data Loading & Inspection\n",
    "\n",
    "### üìÅ Working with Real Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Creating Sample Dataset\n",
      "========================================\n",
      "Sample Sales Dataset Created!\n",
      "Shape: (1000, 9)\n",
      "Date range: 2024-01-01 00:00:00 to 2024-02-11 15:00:00\n"
     ]
    }
   ],
   "source": [
    "# 2.1 Creating Sample Data\n",
    "print(\"üìÅ Creating Sample Dataset\\n\" + \"=\"*40)\n",
    "\n",
    "# Generate a realistic sales dataset\n",
    "np.random.seed(42)\n",
    "n_records = 1000\n",
    "\n",
    "sales_data = pd.DataFrame({\n",
    "    'OrderID': range(1001, 1001 + n_records),\n",
    "    'Date': pd.date_range('2024-01-01', periods=n_records, freq='H'),\n",
    "    'Product': np.random.choice(['Laptop', 'Phone', 'Tablet', 'Watch', 'Headphones'], n_records),\n",
    "    'Category': np.random.choice(['Electronics', 'Accessories'], n_records),\n",
    "    'Quantity': np.random.randint(1, 10, n_records),\n",
    "    'Price': np.random.uniform(50, 2000, n_records).round(2),\n",
    "    'Customer': ['Customer_' + str(i) for i in np.random.randint(1, 200, n_records)],\n",
    "    'City': np.random.choice(['NYC', 'LA', 'Chicago', 'Houston', 'Phoenix'], n_records),\n",
    "    'PaymentMethod': np.random.choice(['Credit', 'Debit', 'Cash', 'PayPal'], n_records)\n",
    "})\n",
    "\n",
    "# Add some missing values for realism\n",
    "sales_data.loc[sales_data.sample(50).index, 'City'] = np.nan\n",
    "sales_data.loc[sales_data.sample(30).index, 'PaymentMethod'] = np.nan\n",
    "\n",
    "print(\"Sample Sales Dataset Created!\")\n",
    "print(f\"Shape: {sales_data.shape}\")\n",
    "print(f\"Date range: {sales_data['Date'].min()} to {sales_data['Date'].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Inspecting the Data\n",
      "========================================\n",
      "First 5 rows:\n",
      "   OrderID                Date     Product     Category  Quantity    Price      Customer     City PaymentMethod\n",
      "0     1001 2024-01-01 00:00:00       Watch  Accessories         7  1260.81  Customer_185      NYC           NaN\n",
      "1     1002 2024-01-01 01:00:00  Headphones  Accessories         1   737.13    Customer_4  Chicago         Debit\n",
      "2     1003 2024-01-01 02:00:00      Tablet  Accessories         8  1690.82  Customer_135  Phoenix        PayPal\n",
      "3     1004 2024-01-01 03:00:00  Headphones  Accessories         3   969.01   Customer_61      NYC           NaN\n",
      "4     1005 2024-01-01 04:00:00  Headphones  Accessories         6  1959.25  Customer_107      NYC          Cash\n",
      "\n",
      "Last 3 rows:\n",
      "     OrderID                Date Product     Category  Quantity    Price      Customer     City PaymentMethod\n",
      "997     1998 2024-02-11 13:00:00  Laptop  Electronics         2  1658.25  Customer_170       LA        PayPal\n",
      "998     1999 2024-02-11 14:00:00   Watch  Accessories         9   620.15  Customer_149       LA        PayPal\n",
      "999     2000 2024-02-11 15:00:00  Tablet  Accessories         7   915.64   Customer_79  Houston         Debit\n",
      "\n",
      "Random 3 rows:\n",
      "     OrderID                Date     Product     Category  Quantity    Price      Customer City PaymentMethod\n",
      "4       1005 2024-01-01 04:00:00  Headphones  Accessories         6  1959.25  Customer_107  NYC          Cash\n",
      "236     1237 2024-01-10 20:00:00      Laptop  Accessories         6    99.62  Customer_107  NYC        PayPal\n",
      "272     1273 2024-01-12 08:00:00      Laptop  Accessories         8   612.39  Customer_144   LA         Debit\n",
      "\n",
      "Numerical columns statistics:\n",
      "           OrderID                           Date     Quantity        Price\n",
      "count  1000.000000                           1000  1000.000000  1000.000000\n",
      "mean   1500.500000  2024-01-21 19:29:59.999999744     5.014000  1024.594930\n",
      "min    1001.000000            2024-01-01 00:00:00     1.000000    50.020000\n",
      "25%    1250.750000            2024-01-11 09:45:00     3.000000   573.182500\n",
      "50%    1500.500000            2024-01-21 19:30:00     5.000000  1024.315000\n",
      "75%    1750.250000            2024-02-01 05:15:00     7.000000  1499.425000\n",
      "max    2000.000000            2024-02-11 15:00:00     9.000000  1995.750000\n",
      "std     288.819436                            NaN     2.531049   564.784299\n",
      "\n",
      "Categorical columns info:\n",
      "       Product     Category     Customer     City PaymentMethod\n",
      "count     1000         1000         1000      950           970\n",
      "unique       5            2          194        5             4\n",
      "top     Laptop  Electronics  Customer_13  Houston         Debit\n",
      "freq       210          513           12      203           281\n"
     ]
    }
   ],
   "source": [
    "# 2.2 Data Inspection Methods\n",
    "print(\"üîç Inspecting the Data\\n\" + \"=\"*40)\n",
    "\n",
    "# First few rows\n",
    "print(\"First 5 rows:\")\n",
    "print(sales_data.head())\n",
    "\n",
    "# Last few rows\n",
    "print(\"\\nLast 3 rows:\")\n",
    "print(sales_data.tail(3))\n",
    "\n",
    "# Random sample\n",
    "print(\"\\nRandom 3 rows:\")\n",
    "print(sales_data.sample(3))\n",
    "\n",
    "# Basic statistics\n",
    "print(\"\\nNumerical columns statistics:\")\n",
    "print(sales_data.describe())\n",
    "\n",
    "# Categorical columns\n",
    "print(\"\\nCategorical columns info:\")\n",
    "print(sales_data.describe(include=['object']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîé Missing Data Analysis\n",
      "========================================\n",
      "Missing values per column:\n",
      "               Missing_Count  Percentage\n",
      "City                      50         5.0\n",
      "PaymentMethod             30         3.0\n",
      "\n",
      "Rows with any missing values: 77\n",
      "Complete rows: 923\n"
     ]
    }
   ],
   "source": [
    "# 2.3 Missing Data Detection\n",
    "print(\"üîé Missing Data Analysis\\n\" + \"=\"*40)\n",
    "\n",
    "# Check for missing values\n",
    "missing = sales_data.isnull().sum()\n",
    "missing_pct = (missing / len(sales_data)) * 100\n",
    "\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing_Count': missing,\n",
    "    'Percentage': missing_pct.round(2)\n",
    "})\n",
    "\n",
    "print(\"Missing values per column:\")\n",
    "print(missing_df[missing_df['Missing_Count'] > 0])\n",
    "\n",
    "# Visualize missing data pattern\n",
    "print(\"\\nRows with any missing values:\", sales_data.isnull().any(axis=1).sum())\n",
    "print(\"Complete rows:\", sales_data.notna().all(axis=1).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìå Section 3: Indexing & Selection - Access Your Data\n",
    "\n",
    "### üéØ Multiple Ways to Select Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Column Selection\n",
      "========================================\n",
      "Single column (Series):\n",
      "0         Watch\n",
      "1    Headphones\n",
      "2        Tablet\n",
      "3    Headphones\n",
      "4    Headphones\n",
      "Name: Product, dtype: object\n",
      "Type: <class 'pandas.core.series.Series'>\n",
      "\n",
      "Multiple columns (DataFrame):\n",
      "      Product    Price  Quantity\n",
      "0       Watch  1260.81         7\n",
      "1  Headphones   737.13         1\n",
      "2      Tablet  1690.82         8\n",
      "3  Headphones   969.01         3\n",
      "4  Headphones  1959.25         6\n",
      "Type: <class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "# 3.1 Column Selection\n",
    "print(\"üìä Column Selection\\n\" + \"=\"*40)\n",
    "\n",
    "# Single column (returns Series)\n",
    "products = sales_data['Product']\n",
    "print(\"Single column (Series):\")\n",
    "print(products.head())\n",
    "print(f\"Type: {type(products)}\")\n",
    "\n",
    "# Multiple columns (returns DataFrame)\n",
    "subset = sales_data[['Product', 'Price', 'Quantity']]\n",
    "print(\"\\nMultiple columns (DataFrame):\")\n",
    "print(subset.head())\n",
    "print(f\"Type: {type(subset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ Row Selection: loc vs iloc\n",
      "========================================\n",
      "Original DataFrame:\n",
      "          Name  Score Grade\n",
      "ST001    Alice     85     B\n",
      "ST002      Bob     92     A\n",
      "ST003  Charlie     78     C\n",
      "ST004    David     95     A\n",
      "ST005     Emma     88     B\n",
      "\n",
      "üè∑Ô∏è Using loc (label-based):\n",
      "Select row 'ST003':\n",
      "Name     Charlie\n",
      "Score         78\n",
      "Grade          C\n",
      "Name: ST003, dtype: object\n",
      "\n",
      "Select rows ST002 to ST004:\n",
      "          Name  Score Grade\n",
      "ST002      Bob     92     A\n",
      "ST003  Charlie     78     C\n",
      "ST004    David     95     A\n",
      "\n",
      "Select specific rows and columns:\n",
      "        Name  Score\n",
      "ST001  Alice     85\n",
      "ST005   Emma     88\n",
      "\n",
      "üî¢ Using iloc (position-based):\n",
      "Select row at position 2:\n",
      "Name     Charlie\n",
      "Score         78\n",
      "Grade          C\n",
      "Name: ST003, dtype: object\n",
      "\n",
      "Select rows 1 to 3:\n",
      "          Name  Score Grade\n",
      "ST002      Bob     92     A\n",
      "ST003  Charlie     78     C\n",
      "ST004    David     95     A\n",
      "\n",
      "Select specific positions:\n",
      "        Name  Score\n",
      "ST001  Alice     85\n",
      "ST005   Emma     88\n"
     ]
    }
   ],
   "source": [
    "# 3.2 Row Selection with loc and iloc\n",
    "print(\"üéØ Row Selection: loc vs iloc\\n\" + \"=\"*40)\n",
    "\n",
    "# Create a simple DataFrame with custom index\n",
    "df = pd.DataFrame({\n",
    "    'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Emma'],\n",
    "    'Score': [85, 92, 78, 95, 88],\n",
    "    'Grade': ['B', 'A', 'C', 'A', 'B']\n",
    "}, index=['ST001', 'ST002', 'ST003', 'ST004', 'ST005'])\n",
    "\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n",
    "\n",
    "# loc: label-based selection\n",
    "print(\"\\nüè∑Ô∏è Using loc (label-based):\")\n",
    "print(\"Select row 'ST003':\")\n",
    "print(df.loc['ST003'])\n",
    "print(\"\\nSelect rows ST002 to ST004:\")\n",
    "print(df.loc['ST002':'ST004'])\n",
    "print(\"\\nSelect specific rows and columns:\")\n",
    "print(df.loc[['ST001', 'ST005'], ['Name', 'Score']])\n",
    "\n",
    "# iloc: integer position-based selection\n",
    "print(\"\\nüî¢ Using iloc (position-based):\")\n",
    "print(\"Select row at position 2:\")\n",
    "print(df.iloc[2])\n",
    "print(\"\\nSelect rows 1 to 3:\")\n",
    "print(df.iloc[1:4])\n",
    "print(\"\\nSelect specific positions:\")\n",
    "print(df.iloc[[0, 4], [0, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Boolean Indexing\n",
      "========================================\n",
      "Products with price > $1000: 511 records\n",
      "      Product    Price\n",
      "0       Watch  1260.81\n",
      "2      Tablet  1690.82\n",
      "4  Headphones  1959.25\n",
      "5       Phone  1286.58\n",
      "7      Tablet  1368.55\n",
      "\n",
      "Laptops sold in NYC: 30 records\n",
      "\n",
      "Sales in NYC or LA: 356 records\n",
      "\n",
      "High value bulk orders: 342 records\n"
     ]
    }
   ],
   "source": [
    "# 3.3 Boolean Indexing (Filtering)\n",
    "print(\"üîç Boolean Indexing\\n\" + \"=\"*40)\n",
    "\n",
    "# Simple filter\n",
    "high_price = sales_data[sales_data['Price'] > 1000]\n",
    "print(f\"Products with price > $1000: {len(high_price)} records\")\n",
    "print(high_price[['Product', 'Price']].head())\n",
    "\n",
    "# Multiple conditions\n",
    "laptops_nyc = sales_data[\n",
    "    (sales_data['Product'] == 'Laptop') & \n",
    "    (sales_data['City'] == 'NYC')\n",
    "]\n",
    "print(f\"\\nLaptops sold in NYC: {len(laptops_nyc)} records\")\n",
    "\n",
    "# Using isin()\n",
    "tech_cities = sales_data[sales_data['City'].isin(['NYC', 'LA'])]\n",
    "print(f\"\\nSales in NYC or LA: {len(tech_cities)} records\")\n",
    "\n",
    "# Using query() method\n",
    "query_result = sales_data.query('Price > 500 and Quantity > 5')\n",
    "print(f\"\\nHigh value bulk orders: {len(query_result)} records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üèãÔ∏è Exercise 2: Data Selection Challenge\n",
    "\n",
    "From the sales_data DataFrame:\n",
    "1. Find all Phone sales with quantity >= 5\n",
    "2. Select orders from January 2024\n",
    "3. Find the top 5 most expensive orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phone bulk orders: 105 records\n",
      "\n",
      "January orders: 744 records\n",
      "\n",
      "Top 5 most expensive orders:\n",
      "     OrderID     Product  TotalValue\n",
      "802     1803       Watch    17623.08\n",
      "880     1881       Watch    17485.38\n",
      "824     1825      Laptop    17421.48\n",
      "807     1808      Tablet    17071.47\n",
      "918     1919  Headphones    17030.16\n"
     ]
    }
   ],
   "source": [
    "# Your solution here:\n",
    "\n",
    "# Solution:\n",
    "# 1. Phone sales with quantity >= 5\n",
    "phone_bulk = sales_data[(sales_data['Product'] == 'Phone') & (sales_data['Quantity'] >= 5)]\n",
    "print(f\"Phone bulk orders: {len(phone_bulk)} records\")\n",
    "\n",
    "# 2. January 2024 orders\n",
    "jan_orders = sales_data[sales_data['Date'].dt.month == 1]\n",
    "print(f\"\\nJanuary orders: {len(jan_orders)} records\")\n",
    "\n",
    "# 3. Top 5 most expensive orders\n",
    "sales_data['TotalValue'] = sales_data['Price'] * sales_data['Quantity']\n",
    "top_5 = sales_data.nlargest(5, 'TotalValue')[['OrderID', 'Product', 'TotalValue']]\n",
    "print(\"\\nTop 5 most expensive orders:\")\n",
    "print(top_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìå Section 4: Data Cleaning - Handle Real-World Messiness\n",
    "\n",
    "### üßπ Clean Your Data Like a Pro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßπ Handling Missing Data\n",
      "========================================\n",
      "Missing values before cleaning:\n",
      "City             50\n",
      "PaymentMethod    30\n",
      "dtype: int64\n",
      "\n",
      "After dropna(): 923 rows (lost 77 rows)\n",
      "\n",
      "After fillna():\n",
      "OrderID          0\n",
      "Date             0\n",
      "Product          0\n",
      "Category         0\n",
      "Quantity         0\n",
      "Price            0\n",
      "Customer         0\n",
      "City             0\n",
      "PaymentMethod    0\n",
      "TotalValue       0\n",
      "dtype: int64\n",
      "\n",
      "Time series with missing values:\n",
      "        Date  Value\n",
      "0 2024-01-01  100.0\n",
      "1 2024-01-02    NaN\n",
      "2 2024-01-03    NaN\n",
      "3 2024-01-04  150.0\n",
      "4 2024-01-05  200.0\n",
      "5 2024-01-06    NaN\n",
      "6 2024-01-07  250.0\n",
      "7 2024-01-08  300.0\n",
      "8 2024-01-09    NaN\n",
      "9 2024-01-10  350.0\n",
      "\n",
      "Forward filled:\n",
      "        Date  Value\n",
      "0 2024-01-01  100.0\n",
      "1 2024-01-02  100.0\n",
      "2 2024-01-03  100.0\n",
      "3 2024-01-04  150.0\n",
      "4 2024-01-05  200.0\n",
      "5 2024-01-06  200.0\n",
      "6 2024-01-07  250.0\n",
      "7 2024-01-08  300.0\n",
      "8 2024-01-09  300.0\n",
      "9 2024-01-10  350.0\n"
     ]
    }
   ],
   "source": [
    "# 4.1 Handling Missing Data\n",
    "print(\"üßπ Handling Missing Data\\n\" + \"=\"*40)\n",
    "\n",
    "# Create sample data with missing values\n",
    "messy_data = sales_data.copy()\n",
    "\n",
    "print(\"Missing values before cleaning:\")\n",
    "print(messy_data.isnull().sum()[messy_data.isnull().sum() > 0])\n",
    "\n",
    "# Method 1: Drop missing values\n",
    "clean_drop = messy_data.dropna()\n",
    "print(f\"\\nAfter dropna(): {len(clean_drop)} rows (lost {len(messy_data) - len(clean_drop)} rows)\")\n",
    "\n",
    "# Method 2: Fill with a value\n",
    "messy_data['City'].fillna('Unknown', inplace=True)\n",
    "messy_data['PaymentMethod'].fillna('Cash', inplace=True)\n",
    "\n",
    "print(\"\\nAfter fillna():\")\n",
    "print(messy_data.isnull().sum())\n",
    "\n",
    "# Method 3: Forward/Backward fill\n",
    "time_series = pd.DataFrame({\n",
    "    'Date': pd.date_range('2024-01-01', periods=10),\n",
    "    'Value': [100, np.nan, np.nan, 150, 200, np.nan, 250, 300, np.nan, 350]\n",
    "})\n",
    "\n",
    "print(\"\\nTime series with missing values:\")\n",
    "print(time_series)\n",
    "\n",
    "print(\"\\nForward filled:\")\n",
    "print(time_series.fillna(method='ffill'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Removing Duplicates\n",
      "========================================\n",
      "Original data with duplicates:\n",
      "   ID     Name  Score\n",
      "0   1    Alice     85\n",
      "1   2      Bob     90\n",
      "2   2      Bob     90\n",
      "3   3  Charlie     75\n",
      "4   4    David     88\n",
      "5   4    David     88\n",
      "6   4    David     92\n",
      "7   5     Emma     95\n",
      "\n",
      "Duplicate rows: 2\n",
      "\n",
      "Duplicate rows details:\n",
      "   ID   Name  Score\n",
      "1   2    Bob     90\n",
      "2   2    Bob     90\n",
      "4   4  David     88\n",
      "5   4  David     88\n",
      "\n",
      "After removing duplicates: 6 rows\n",
      "   ID     Name  Score\n",
      "0   1    Alice     85\n",
      "1   2      Bob     90\n",
      "3   3  Charlie     75\n",
      "4   4    David     88\n",
      "6   4    David     92\n",
      "7   5     Emma     95\n",
      "\n",
      "Keeping last occurrence per ID:\n",
      "   ID     Name  Score\n",
      "0   1    Alice     85\n",
      "2   2      Bob     90\n",
      "3   3  Charlie     75\n",
      "6   4    David     92\n",
      "7   5     Emma     95\n"
     ]
    }
   ],
   "source": [
    "# 4.2 Removing Duplicates\n",
    "print(\"üîÑ Removing Duplicates\\n\" + \"=\"*40)\n",
    "\n",
    "# Create data with duplicates\n",
    "dup_data = pd.DataFrame({\n",
    "    'ID': [1, 2, 2, 3, 4, 4, 4, 5],\n",
    "    'Name': ['Alice', 'Bob', 'Bob', 'Charlie', 'David', 'David', 'David', 'Emma'],\n",
    "    'Score': [85, 90, 90, 75, 88, 88, 92, 95]\n",
    "})\n",
    "\n",
    "print(\"Original data with duplicates:\")\n",
    "print(dup_data)\n",
    "\n",
    "# Check for duplicates\n",
    "print(f\"\\nDuplicate rows: {dup_data.duplicated().sum()}\")\n",
    "print(\"\\nDuplicate rows details:\")\n",
    "print(dup_data[dup_data.duplicated(keep=False)])\n",
    "\n",
    "# Remove duplicates\n",
    "clean_data = dup_data.drop_duplicates()\n",
    "print(f\"\\nAfter removing duplicates: {len(clean_data)} rows\")\n",
    "print(clean_data)\n",
    "\n",
    "# Keep last occurrence\n",
    "keep_last = dup_data.drop_duplicates(subset=['ID'], keep='last')\n",
    "print(\"\\nKeeping last occurrence per ID:\")\n",
    "print(keep_last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Data Type Conversions\n",
      "========================================\n",
      "Original data types:\n",
      "ID         object\n",
      "Price      object\n",
      "Date       object\n",
      "InStock    object\n",
      "dtype: object\n",
      "\n",
      "Data:\n",
      "    ID  Price        Date InStock\n",
      "0  001  19.99  2024-01-01    True\n",
      "1  002  29.99  2024-01-02   False\n",
      "2  003  39.99  2024-01-03    True\n",
      "3  004  49.99  2024-01-04    True\n",
      "\n",
      "Corrected data types:\n",
      "ID                  int32\n",
      "Price             float64\n",
      "Date       datetime64[ns]\n",
      "InStock              bool\n",
      "dtype: object\n",
      "\n",
      "Data after conversion:\n",
      "   ID  Price       Date  InStock\n",
      "0   1  19.99 2024-01-01     True\n",
      "1   2  29.99 2024-01-02    False\n",
      "2   3  39.99 2024-01-03     True\n",
      "3   4  49.99 2024-01-04     True\n"
     ]
    }
   ],
   "source": [
    "# 4.3 Data Type Conversions\n",
    "print(\"üîß Data Type Conversions\\n\" + \"=\"*40)\n",
    "\n",
    "# Create sample data with wrong types\n",
    "wrong_types = pd.DataFrame({\n",
    "    'ID': ['001', '002', '003', '004'],\n",
    "    'Price': ['19.99', '29.99', '39.99', '49.99'],\n",
    "    'Date': ['2024-01-01', '2024-01-02', '2024-01-03', '2024-01-04'],\n",
    "    'InStock': ['True', 'False', 'True', 'True']\n",
    "})\n",
    "\n",
    "print(\"Original data types:\")\n",
    "print(wrong_types.dtypes)\n",
    "print(\"\\nData:\")\n",
    "print(wrong_types)\n",
    "\n",
    "# Convert to appropriate types\n",
    "wrong_types['ID'] = wrong_types['ID'].astype(int)\n",
    "wrong_types['Price'] = wrong_types['Price'].astype(float)\n",
    "wrong_types['Date'] = pd.to_datetime(wrong_types['Date'])\n",
    "wrong_types['InStock'] = wrong_types['InStock'].map({'True': True, 'False': False})\n",
    "\n",
    "print(\"\\nCorrected data types:\")\n",
    "print(wrong_types.dtypes)\n",
    "print(\"\\nData after conversion:\")\n",
    "print(wrong_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù String Operations\n",
      "========================================\n",
      "Original messy text data:\n",
      "           Name              Email           Phone\n",
      "0    John Doe       JOHN@GMAIL.COM    123-456-7890\n",
      "1    jane smith     Jane@Yahoo.com  (555) 123-4567\n",
      "2   BOB JOHNSON    bob@HOTMAIL.COM      9876543210\n",
      "3   Alice_Brown  alice@outlook.com    555.123.4567\n",
      "\n",
      "Cleaned text data:\n",
      "          Name              Email           Phone Phone_Clean\n",
      "0     John Doe     john@gmail.com    123-456-7890  1234567890\n",
      "1   Jane Smith     jane@yahoo.com  (555) 123-4567  5551234567\n",
      "2  Bob Johnson    bob@hotmail.com      9876543210  9876543210\n",
      "3  Alice Brown  alice@outlook.com    555.123.4567  5551234567\n",
      "\n",
      "Gmail users: 1\n"
     ]
    }
   ],
   "source": [
    "# 4.4 String Operations\n",
    "print(\"üìù String Operations\\n\" + \"=\"*40)\n",
    "\n",
    "# Create sample data\n",
    "text_data = pd.DataFrame({\n",
    "    'Name': ['  John Doe  ', 'jane smith', 'BOB JOHNSON', 'Alice_Brown'],\n",
    "    'Email': ['JOHN@GMAIL.COM', 'Jane@Yahoo.com', 'bob@HOTMAIL.COM', 'alice@outlook.com'],\n",
    "    'Phone': ['123-456-7890', '(555) 123-4567', '9876543210', '555.123.4567']\n",
    "})\n",
    "\n",
    "print(\"Original messy text data:\")\n",
    "print(text_data)\n",
    "\n",
    "# Clean the data\n",
    "text_data['Name'] = text_data['Name'].str.strip()  # Remove spaces\n",
    "text_data['Name'] = text_data['Name'].str.title()  # Title case\n",
    "text_data['Name'] = text_data['Name'].str.replace('_', ' ')  # Replace underscore\n",
    "\n",
    "text_data['Email'] = text_data['Email'].str.lower()  # Lowercase emails\n",
    "\n",
    "# Extract phone digits only\n",
    "text_data['Phone_Clean'] = text_data['Phone'].str.replace(r'\\D', '', regex=True)\n",
    "\n",
    "print(\"\\nCleaned text data:\")\n",
    "print(text_data)\n",
    "\n",
    "# String contains\n",
    "gmail_users = text_data[text_data['Email'].str.contains('gmail')]\n",
    "print(f\"\\nGmail users: {len(gmail_users)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìå Section 5: Data Transformation - Apply, Map, and More\n",
    "\n",
    "### üîÑ Transform Your Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Apply Functions\n",
      "========================================\n",
      "Original DataFrame:\n",
      "   Price  Quantity  Discount\n",
      "0    100         2      0.10\n",
      "1    200         1      0.15\n",
      "2    150         3      0.20\n",
      "3    300         2      0.05\n",
      "4    250         4      0.10\n",
      "\n",
      "After applying discount logic:\n",
      "   Price  Quantity  Discount  Total  Final_Price\n",
      "0    100         2      0.10    200        200.0\n",
      "1    200         1      0.15    200        200.0\n",
      "2    150         3      0.20    450        450.0\n",
      "3    300         2      0.05    600        540.0\n",
      "4    250         4      0.10   1000        900.0\n",
      "\n",
      "With revenue calculation:\n",
      "   Price  Quantity  Discount  Total  Final_Price  Revenue\n",
      "0    100         2      0.10    200        200.0    180.0\n",
      "1    200         1      0.15    200        200.0    170.0\n",
      "2    150         3      0.20    450        450.0    360.0\n",
      "3    300         2      0.05    600        540.0    570.0\n",
      "4    250         4      0.10   1000        900.0    900.0\n"
     ]
    }
   ],
   "source": [
    "# 5.1 Apply Functions\n",
    "print(\"üîß Apply Functions\\n\" + \"=\"*40)\n",
    "\n",
    "# Sample data\n",
    "df = pd.DataFrame({\n",
    "    'Price': [100, 200, 150, 300, 250],\n",
    "    'Quantity': [2, 1, 3, 2, 4],\n",
    "    'Discount': [0.1, 0.15, 0.2, 0.05, 0.1]\n",
    "})\n",
    "\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n",
    "\n",
    "# Apply to Series\n",
    "df['Total'] = df['Price'] * df['Quantity']\n",
    "df['Final_Price'] = df['Total'].apply(lambda x: x * 0.9 if x > 500 else x)\n",
    "\n",
    "print(\"\\nAfter applying discount logic:\")\n",
    "print(df)\n",
    "\n",
    "# Apply to DataFrame rows\n",
    "def calculate_revenue(row):\n",
    "    base = row['Price'] * row['Quantity']\n",
    "    return base * (1 - row['Discount'])\n",
    "\n",
    "df['Revenue'] = df.apply(calculate_revenue, axis=1)\n",
    "\n",
    "print(\"\\nWith revenue calculation:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üó∫Ô∏è Map and Replace\n",
      "========================================\n",
      "Original DataFrame:\n",
      "  Grade Status\n",
      "0     A   Pass\n",
      "1     B   Pass\n",
      "2     C   Pass\n",
      "3     A   Pass\n",
      "4     B   Pass\n",
      "5     D   Fail\n",
      "6     A   Pass\n",
      "7     C   Pass\n",
      "\n",
      "After mapping and replacing:\n",
      "  Grade Status  GPA  Status_Code\n",
      "0     A   Pass  4.0            1\n",
      "1     B   Pass  3.0            1\n",
      "2     C   Pass  2.0            1\n",
      "3     A   Pass  4.0            1\n",
      "4     B   Pass  3.0            1\n",
      "5     D   Fail  1.0            0\n",
      "6     A   Pass  4.0            1\n",
      "7     C   Pass  2.0            1\n",
      "\n",
      "Binning scores into grades:\n",
      "   Score Grade\n",
      "0     45     F\n",
      "1     67     D\n",
      "2     89     B\n",
      "3     72     C\n",
      "4     91     A\n",
      "5     55     F\n",
      "6     78     C\n",
      "7     83     B\n",
      "8     62     D\n",
      "9     95     A\n"
     ]
    }
   ],
   "source": [
    "# 5.2 Map and Replace\n",
    "print(\"üó∫Ô∏è Map and Replace\\n\" + \"=\"*40)\n",
    "\n",
    "# Sample data\n",
    "df = pd.DataFrame({\n",
    "    'Grade': ['A', 'B', 'C', 'A', 'B', 'D', 'A', 'C'],\n",
    "    'Status': ['Pass', 'Pass', 'Pass', 'Pass', 'Pass', 'Fail', 'Pass', 'Pass']\n",
    "})\n",
    "\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n",
    "\n",
    "# Map values\n",
    "grade_points = {'A': 4.0, 'B': 3.0, 'C': 2.0, 'D': 1.0, 'F': 0.0}\n",
    "df['GPA'] = df['Grade'].map(grade_points)\n",
    "\n",
    "# Replace values\n",
    "df['Status_Code'] = df['Status'].replace({'Pass': 1, 'Fail': 0})\n",
    "\n",
    "print(\"\\nAfter mapping and replacing:\")\n",
    "print(df)\n",
    "\n",
    "# Binning continuous values\n",
    "scores = pd.DataFrame({'Score': [45, 67, 89, 72, 91, 55, 78, 83, 62, 95]})\n",
    "bins = [0, 60, 70, 80, 90, 100]\n",
    "labels = ['F', 'D', 'C', 'B', 'A']\n",
    "scores['Grade'] = pd.cut(scores['Score'], bins=bins, labels=labels)\n",
    "\n",
    "print(\"\\nBinning scores into grades:\")\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèóÔ∏è Feature Engineering\n",
      "========================================\n",
      "New features created:\n",
      "                 Date  Year  Month  Day DayOfWeek  IsWeekend PriceCategory\n",
      "0 2024-01-01 00:00:00  2024      1    1    Monday      False        Medium\n",
      "1 2024-01-01 01:00:00  2024      1    1    Monday      False        Medium\n",
      "2 2024-01-01 02:00:00  2024      1    1    Monday      False          High\n",
      "3 2024-01-01 03:00:00  2024      1    1    Monday      False        Medium\n",
      "4 2024-01-01 04:00:00  2024      1    1    Monday      False          High\n",
      "\n",
      "Customer statistics (first 5):\n",
      "             OrderID TotalValue          \n",
      "               count        sum      mean\n",
      "Customer                                 \n",
      "Customer_1         2   23086.60  11543.30\n",
      "Customer_10        2    5412.62   2706.31\n",
      "Customer_100       2    4221.74   2110.87\n",
      "Customer_101       4   23799.22   5949.80\n",
      "Customer_102       4   22924.73   5731.18\n"
     ]
    }
   ],
   "source": [
    "# 5.3 Creating New Features\n",
    "print(\"üèóÔ∏è Feature Engineering\\n\" + \"=\"*40)\n",
    "\n",
    "# Work with the sales data\n",
    "df = sales_data.copy()\n",
    "\n",
    "# Extract date features\n",
    "df['Year'] = df['Date'].dt.year\n",
    "df['Month'] = df['Date'].dt.month\n",
    "df['Day'] = df['Date'].dt.day\n",
    "df['DayOfWeek'] = df['Date'].dt.day_name()\n",
    "df['Hour'] = df['Date'].dt.hour\n",
    "df['IsWeekend'] = df['Date'].dt.dayofweek.isin([5, 6])\n",
    "\n",
    "# Calculate features\n",
    "df['TotalValue'] = df['Price'] * df['Quantity']\n",
    "df['PriceCategory'] = pd.qcut(df['Price'], q=3, labels=['Low', 'Medium', 'High'])\n",
    "\n",
    "print(\"New features created:\")\n",
    "print(df[['Date', 'Year', 'Month', 'Day', 'DayOfWeek', 'IsWeekend', 'PriceCategory']].head())\n",
    "\n",
    "# Aggregate features\n",
    "customer_stats = df.groupby('Customer').agg({\n",
    "    'OrderID': 'count',\n",
    "    'TotalValue': ['sum', 'mean']\n",
    "}).round(2)\n",
    "\n",
    "print(\"\\nCustomer statistics (first 5):\")\n",
    "print(customer_stats.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìå Section 6: Grouping & Aggregation - SQL-like Operations\n",
    "\n",
    "### üìä GROUP BY in Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä GroupBy Operations\n",
      "========================================\n",
      "Sales by Product:\n",
      "            count     mean        sum\n",
      "Product                              \n",
      "Headphones    204  1098.42  224077.93\n",
      "Laptop        210  1000.27  210056.70\n",
      "Phone         190  1041.24  197835.30\n",
      "Tablet        190  1022.59  194291.43\n",
      "Watch         206   962.78  198333.57\n",
      "\n",
      "Detailed Product Summary:\n",
      "            OrderID_count  Quantity_sum  Price_mean  Price_min  Price_max\n",
      "Product                                                                  \n",
      "Headphones            204           985     1098.42      50.02    1991.10\n",
      "Laptop                210          1097     1000.27      66.22    1988.00\n",
      "Phone                 190           943     1041.24      67.63    1970.47\n",
      "Tablet                190           985     1022.59      50.26    1949.68\n",
      "Watch                 206          1004      962.78      52.87    1995.75\n"
     ]
    }
   ],
   "source": [
    "# 6.1 Basic GroupBy\n",
    "print(\"üìä GroupBy Operations\\n\" + \"=\"*40)\n",
    "\n",
    "# Group by single column\n",
    "product_groups = sales_data.groupby('Product')\n",
    "\n",
    "# Basic aggregations\n",
    "print(\"Sales by Product:\")\n",
    "print(product_groups['Price'].agg(['count', 'mean', 'sum']).round(2))\n",
    "\n",
    "# Multiple aggregations\n",
    "summary = sales_data.groupby('Product').agg({\n",
    "    'OrderID': 'count',\n",
    "    'Quantity': 'sum',\n",
    "    'Price': ['mean', 'min', 'max']\n",
    "}).round(2)\n",
    "\n",
    "# Flatten column names\n",
    "summary.columns = ['_'.join(col).strip() for col in summary.columns]\n",
    "print(\"\\nDetailed Product Summary:\")\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Multi-level GroupBy\n",
      "========================================\n",
      "Sales by City and Product:\n",
      "                    count     mean\n",
      "City    Product                   \n",
      "Chicago Headphones     44   953.61\n",
      "        Laptop         41  1022.34\n",
      "        Phone          35  1216.69\n",
      "        Tablet         31  1087.79\n",
      "        Watch          46  1050.31\n",
      "Houston Headphones     41  1131.12\n",
      "        Laptop         41  1013.16\n",
      "        Phone          39  1001.79\n",
      "        Tablet         43  1021.49\n",
      "        Watch          39   902.02\n",
      "\n",
      "Pivot Table - Average Price by Product and City:\n",
      "City        Chicago  Houston       LA      NYC  Phoenix\n",
      "Product                                                \n",
      "Headphones   953.61  1131.12  1117.24   968.32  1337.90\n",
      "Laptop      1022.34  1013.16  1100.04   840.98   986.86\n",
      "Phone       1216.69  1001.79   952.15  1145.84   897.69\n",
      "Tablet      1087.79  1021.49  1231.85   885.36   852.06\n",
      "Watch       1050.31   902.02   970.20   998.87   901.79\n"
     ]
    }
   ],
   "source": [
    "# 6.2 Multi-level GroupBy\n",
    "print(\"üìä Multi-level GroupBy\\n\" + \"=\"*40)\n",
    "\n",
    "# Group by multiple columns\n",
    "city_product = sales_data.groupby(['City', 'Product'])['Price'].agg(['count', 'mean'])\n",
    "city_product = city_product.round(2)\n",
    "\n",
    "print(\"Sales by City and Product:\")\n",
    "print(city_product.head(10))\n",
    "\n",
    "# Pivot table alternative\n",
    "pivot = sales_data.pivot_table(\n",
    "    values='Price',\n",
    "    index='Product',\n",
    "    columns='City',\n",
    "    aggfunc='mean',\n",
    "    fill_value=0\n",
    ").round(2)\n",
    "\n",
    "print(\"\\nPivot Table - Average Price by Product and City:\")\n",
    "print(pivot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Transform and Filter Groups\n",
      "========================================\n",
      "Data with group statistics:\n",
      "      Product    Price  Product_Avg_Price  Price_vs_Avg\n",
      "0       Watch  1260.81         962.784320    298.025680\n",
      "1  Headphones   737.13        1098.421225   -361.291225\n",
      "2      Tablet  1690.82        1022.586474    668.233526\n",
      "3  Headphones   969.01        1098.421225   -129.411225\n",
      "4  Headphones  1959.25        1098.421225    860.828775\n",
      "5       Phone  1286.58        1041.238421    245.341579\n",
      "6      Tablet   296.22        1022.586474   -726.366474\n",
      "7      Tablet  1368.55        1022.586474    345.963526\n",
      "8      Tablet   683.95        1022.586474   -338.636474\n",
      "9  Headphones  1388.34        1098.421225    289.918775\n",
      "\n",
      "Products with >100 sales: 5\n",
      "Total records: 1000\n"
     ]
    }
   ],
   "source": [
    "# 6.3 Transform and Filter Groups\n",
    "print(\"üîÑ Transform and Filter Groups\\n\" + \"=\"*40)\n",
    "\n",
    "# Add group statistics to original data\n",
    "df = sales_data.copy()\n",
    "df['TotalValue'] = df['Price'] * df['Quantity']\n",
    "\n",
    "# Add group means\n",
    "df['Product_Avg_Price'] = df.groupby('Product')['Price'].transform('mean')\n",
    "df['Price_vs_Avg'] = df['Price'] - df['Product_Avg_Price']\n",
    "\n",
    "print(\"Data with group statistics:\")\n",
    "print(df[['Product', 'Price', 'Product_Avg_Price', 'Price_vs_Avg']].head(10))\n",
    "\n",
    "# Filter groups\n",
    "# Keep only products with more than 100 sales\n",
    "popular_products = df.groupby('Product').filter(lambda x: len(x) > 100)\n",
    "print(f\"\\nProducts with >100 sales: {popular_products['Product'].nunique()}\")\n",
    "print(f\"Total records: {len(popular_products)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìå Section 7: Merging & Joining - Combine Your Data\n",
    "\n",
    "### üîó SQL-like JOINs in Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîó Merge Operations\n",
      "========================================\n",
      "Customers:\n",
      "   CustomerID     Name     City\n",
      "0           1    Alice      NYC\n",
      "1           2      Bob       LA\n",
      "2           3  Charlie  Chicago\n",
      "3           4    David  Houston\n",
      "4           5     Emma  Phoenix\n",
      "\n",
      "Orders:\n",
      "   OrderID  CustomerID Product  Amount\n",
      "0      101           1  Laptop    1200\n",
      "1      102           2   Phone     800\n",
      "2      103           1  Tablet     600\n",
      "3      104           3  Laptop    1500\n",
      "4      105           5   Phone     900\n",
      "5      106           2   Watch     400\n",
      "\n",
      "Inner Join Result:\n",
      "   CustomerID     Name     City  OrderID Product  Amount\n",
      "0           1    Alice      NYC      101  Laptop    1200\n",
      "1           1    Alice      NYC      103  Tablet     600\n",
      "2           2      Bob       LA      102   Phone     800\n",
      "3           2      Bob       LA      106   Watch     400\n",
      "4           3  Charlie  Chicago      104  Laptop    1500\n",
      "5           5     Emma  Phoenix      105   Phone     900\n",
      "\n",
      "Left Join Result (all customers):\n",
      "   CustomerID     Name     City  OrderID Product  Amount\n",
      "0           1    Alice      NYC    101.0  Laptop  1200.0\n",
      "1           1    Alice      NYC    103.0  Tablet   600.0\n",
      "2           2      Bob       LA    102.0   Phone   800.0\n",
      "3           2      Bob       LA    106.0   Watch   400.0\n",
      "4           3  Charlie  Chicago    104.0  Laptop  1500.0\n",
      "5           4    David  Houston      NaN     NaN     NaN\n",
      "6           5     Emma  Phoenix    105.0   Phone   900.0\n"
     ]
    }
   ],
   "source": [
    "# 7.1 Merge Operations\n",
    "print(\"üîó Merge Operations\\n\" + \"=\"*40)\n",
    "\n",
    "# Create sample DataFrames\n",
    "customers = pd.DataFrame({\n",
    "    'CustomerID': [1, 2, 3, 4, 5],\n",
    "    'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Emma'],\n",
    "    'City': ['NYC', 'LA', 'Chicago', 'Houston', 'Phoenix']\n",
    "})\n",
    "\n",
    "orders = pd.DataFrame({\n",
    "    'OrderID': [101, 102, 103, 104, 105, 106],\n",
    "    'CustomerID': [1, 2, 1, 3, 5, 2],\n",
    "    'Product': ['Laptop', 'Phone', 'Tablet', 'Laptop', 'Phone', 'Watch'],\n",
    "    'Amount': [1200, 800, 600, 1500, 900, 400]\n",
    "})\n",
    "\n",
    "print(\"Customers:\")\n",
    "print(customers)\n",
    "print(\"\\nOrders:\")\n",
    "print(orders)\n",
    "\n",
    "# Inner join (default)\n",
    "inner_join = pd.merge(customers, orders, on='CustomerID')\n",
    "print(\"\\nInner Join Result:\")\n",
    "print(inner_join)\n",
    "\n",
    "# Left join\n",
    "left_join = pd.merge(customers, orders, on='CustomerID', how='left')\n",
    "print(\"\\nLeft Join Result (all customers):\")\n",
    "print(left_join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìö Concatenation\n",
      "========================================\n",
      "Vertical Concatenation:\n",
      "  Month  Sales\n",
      "0   Jan    100\n",
      "1   Feb    120\n",
      "2   Mar    140\n",
      "3   Apr    130\n",
      "4   May    150\n",
      "5   Jun    160\n",
      "\n",
      "Horizontal Concatenation:\n",
      "  Month  Sales  Revenue\n",
      "0   Jan    100    10000\n",
      "1   Feb    120    12000\n",
      "2   Mar    140    14000\n"
     ]
    }
   ],
   "source": [
    "# 7.2 Concatenation\n",
    "print(\"üìö Concatenation\\n\" + \"=\"*40)\n",
    "\n",
    "# Create sample DataFrames\n",
    "q1_sales = pd.DataFrame({\n",
    "    'Month': ['Jan', 'Feb', 'Mar'],\n",
    "    'Sales': [100, 120, 140]\n",
    "})\n",
    "\n",
    "q2_sales = pd.DataFrame({\n",
    "    'Month': ['Apr', 'May', 'Jun'],\n",
    "    'Sales': [130, 150, 160]\n",
    "})\n",
    "\n",
    "# Vertical concatenation\n",
    "half_year = pd.concat([q1_sales, q2_sales], ignore_index=True)\n",
    "print(\"Vertical Concatenation:\")\n",
    "print(half_year)\n",
    "\n",
    "# Horizontal concatenation\n",
    "revenue = pd.DataFrame({\n",
    "    'Month': ['Jan', 'Feb', 'Mar'],\n",
    "    'Revenue': [10000, 12000, 14000]\n",
    "})\n",
    "\n",
    "combined = pd.concat([q1_sales, revenue[['Revenue']]], axis=1)\n",
    "print(\"\\nHorizontal Concatenation:\")\n",
    "print(combined)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìå Section 8: Time Series Analysis\n",
    "\n",
    "### ‚è∞ Working with Dates and Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÖ Date Operations\n",
      "========================================\n",
      "Time Series Data:\n",
      "                 Sales  Temperature\n",
      "Date                               \n",
      "2024-01-01  100.332999    20.000000\n",
      "2024-01-02  100.135998    20.344267\n",
      "2024-01-03  100.435514    20.688432\n",
      "2024-01-04   99.985298    21.032393\n",
      "2024-01-05  100.700114    21.376049\n",
      "\n",
      "Monthly Averages:\n",
      "                 Sales  Temperature\n",
      "Date                               \n",
      "2024-01-31  100.781140    25.046746\n",
      "2024-02-29  104.429304    33.844528\n",
      "2024-03-31  104.096512    38.995555\n",
      "2024-04-30  103.893286    39.186639\n",
      "2024-05-31  100.518349    34.184007\n",
      "\n",
      "With Moving Averages:\n",
      "                 Sales   Sales_MA7  Sales_MA30\n",
      "Date                                          \n",
      "2024-01-01  100.332999         NaN         NaN\n",
      "2024-01-02  100.135998         NaN         NaN\n",
      "2024-01-03  100.435514         NaN         NaN\n",
      "2024-01-04   99.985298         NaN         NaN\n",
      "2024-01-05  100.700114         NaN         NaN\n",
      "...                ...         ...         ...\n",
      "2024-01-31  103.754640  101.573855  100.796078\n",
      "2024-02-01  105.240228  102.270367  100.966219\n",
      "2024-02-02  106.002671  103.014790  101.151791\n",
      "2024-02-03  104.061091  103.410727  101.287651\n",
      "2024-02-04  104.667110  103.887045  101.419884\n",
      "\n",
      "[35 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# 8.1 Date Operations\n",
    "print(\"üìÖ Date Operations\\n\" + \"=\"*40)\n",
    "\n",
    "# Create time series data\n",
    "dates = pd.date_range('2024-01-01', periods=365, freq='D')\n",
    "ts_data = pd.DataFrame({\n",
    "    'Date': dates,\n",
    "    'Sales': np.random.randn(365).cumsum() + 100,\n",
    "    'Temperature': np.sin(np.arange(365) * 2 * np.pi / 365) * 20 + 20\n",
    "})\n",
    "\n",
    "ts_data.set_index('Date', inplace=True)\n",
    "\n",
    "print(\"Time Series Data:\")\n",
    "print(ts_data.head())\n",
    "\n",
    "# Resampling\n",
    "monthly = ts_data.resample('M').mean()\n",
    "print(\"\\nMonthly Averages:\")\n",
    "print(monthly.head())\n",
    "\n",
    "# Rolling windows\n",
    "ts_data['Sales_MA7'] = ts_data['Sales'].rolling(window=7).mean()\n",
    "ts_data['Sales_MA30'] = ts_data['Sales'].rolling(window=30).mean()\n",
    "\n",
    "print(\"\\nWith Moving Averages:\")\n",
    "print(ts_data[['Sales', 'Sales_MA7', 'Sales_MA30']].head(35))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 8.2 Date Range Filtering\n",
    "# print(\"üîç Date Filtering\\n\" + \"=\"*40)\n",
    "\n",
    "# # Filter by date range\n",
    "# jan_data = ts_data['2024-01']\n",
    "# print(f\"January 2024 data: {len(jan_data)} days\")\n",
    "# print(jan_data.head())\n",
    "\n",
    "# # Between dates\n",
    "# q1_data = ts_data['2024-01-01':'2024-03-31']\n",
    "# print(f\"\\nQ1 2024 data: {len(q1_data)} days\")\n",
    "\n",
    "# # Shift operations\n",
    "# ts_data['Sales_Yesterday'] = ts_data['Sales'].shift(1)\n",
    "# ts_data['Sales_Change'] = ts_data['Sales'] - ts_data['Sales_Yesterday']\n",
    "\n",
    "# print(\"\\nWith lag features:\")\n",
    "# print(ts_data[['Sales', 'Sales_Yesterday', 'Sales_Change']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìå Section 9: Visualization with Pandas\n",
    "\n",
    "### üìà Quick Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìà Pandas Plotting\n",
      "========================================\n",
      "1. Line Plot: ts_data['Sales'].plot()\n",
      "   - Shows sales trend over time\n",
      "\n",
      "2. Bar Plot: product_sales.plot(kind='bar')\n",
      "   - Shows count of sales per product\n",
      "\n",
      "3. Histogram: sales_data['Price'].plot(kind='hist', bins=30)\n",
      "   - Shows distribution of prices\n",
      "\n",
      "4. Box Plot: sales_data.boxplot(column='Price', by='Product')\n",
      "   - Shows price distribution by product\n",
      "\n",
      "5. Scatter Plot: sales_data.plot(x='Quantity', y='Price', kind='scatter')\n",
      "   - Shows relationship between quantity and price\n"
     ]
    }
   ],
   "source": [
    "# 9.1 Basic Plotting\n",
    "print(\"üìà Pandas Plotting\\n\" + \"=\"*40)\n",
    "\n",
    "# Note: In real notebook, these would display as plots\n",
    "# Here we'll describe what would be plotted\n",
    "\n",
    "# Line plot\n",
    "print(\"1. Line Plot: ts_data['Sales'].plot()\")\n",
    "print(\"   - Shows sales trend over time\")\n",
    "\n",
    "# Bar plot\n",
    "product_sales = sales_data.groupby('Product')['Price'].count()\n",
    "print(\"\\n2. Bar Plot: product_sales.plot(kind='bar')\")\n",
    "print(\"   - Shows count of sales per product\")\n",
    "\n",
    "# Histogram\n",
    "print(\"\\n3. Histogram: sales_data['Price'].plot(kind='hist', bins=30)\")\n",
    "print(\"   - Shows distribution of prices\")\n",
    "\n",
    "# Box plot\n",
    "print(\"\\n4. Box Plot: sales_data.boxplot(column='Price', by='Product')\")\n",
    "print(\"   - Shows price distribution by product\")\n",
    "\n",
    "# Scatter plot\n",
    "print(\"\\n5. Scatter Plot: sales_data.plot(x='Quantity', y='Price', kind='scatter')\")\n",
    "print(\"   - Shows relationship between quantity and price\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéØ Section 10: Real-World Projects\n",
    "\n",
    "### Project 1: Customer Analytics Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä CUSTOMER ANALYTICS DASHBOARD\n",
      "==================================================\n",
      "Customer Segmentation:\n",
      "              Orders   Revenue  DaysSinceLastOrder   Segment\n",
      "Customer                                                    \n",
      "Customer_1         2  23086.60                   9  Platinum\n",
      "Customer_10        2   5412.62                   4      Gold\n",
      "Customer_100       2   4221.74                  24    Silver\n",
      "Customer_101       4  23799.22                   0  Platinum\n",
      "Customer_102       4  22924.73                   1  Platinum\n",
      "Customer_103       5  25454.93                   0  Platinum\n",
      "Customer_104      11  68279.90                   1  Platinum\n",
      "Customer_105       2   9657.99                   4      Gold\n",
      "Customer_106       3  13875.98                  15  Platinum\n",
      "Customer_107       5  32246.14                   2  Platinum\n",
      "\n",
      "Segment Analysis:\n",
      "         Orders           Revenue           DaysSinceLastOrder\n",
      "          count  mean         sum      mean               mean\n",
      "Segment                                                       \n",
      "Bronze        0   NaN        0.00       NaN                NaN\n",
      "Silver        6  2.17    15188.43   2531.41              18.67\n",
      "Gold         16  2.88   131616.49   8226.03              14.31\n",
      "Platinum    172  5.47  4997089.75  29052.85               6.16\n",
      "\n",
      "Top 5 Customers:\n",
      "              Orders   Revenue   Segment\n",
      "Customer                                \n",
      "Customer_61       10  69797.85  Platinum\n",
      "Customer_104      11  68279.90  Platinum\n",
      "Customer_110       7  65688.77  Platinum\n",
      "Customer_177      10  59990.64  Platinum\n",
      "Customer_195      10  56244.70  Platinum\n",
      "\n",
      "Churn Risk (No order in 30+ days):\n",
      "             Orders  Revenue  DaysSinceLastOrder\n",
      "Customer                                        \n",
      "Customer_33       2  5746.13                  36\n"
     ]
    }
   ],
   "source": [
    "# Project 1: Customer Analytics\n",
    "print(\"üìä CUSTOMER ANALYTICS DASHBOARD\\n\" + \"=\"*50)\n",
    "\n",
    "# Prepare the data\n",
    "df = sales_data.copy()\n",
    "df['TotalValue'] = df['Price'] * df['Quantity']\n",
    "df['Month'] = df['Date'].dt.to_period('M')\n",
    "\n",
    "# 1. Customer Segmentation\n",
    "customer_summary = df.groupby('Customer').agg({\n",
    "    'OrderID': 'count',\n",
    "    'TotalValue': 'sum',\n",
    "    'Date': lambda x: (df['Date'].max() - x.max()).days\n",
    "}).rename(columns={\n",
    "    'OrderID': 'Orders',\n",
    "    'TotalValue': 'Revenue',\n",
    "    'Date': 'DaysSinceLastOrder'\n",
    "})\n",
    "\n",
    "# Categorize customers\n",
    "customer_summary['Segment'] = pd.cut(\n",
    "    customer_summary['Revenue'],\n",
    "    bins=[0, 1000, 5000, 10000, float('inf')],\n",
    "    labels=['Bronze', 'Silver', 'Gold', 'Platinum']\n",
    ")\n",
    "\n",
    "print(\"Customer Segmentation:\")\n",
    "print(customer_summary.head(10))\n",
    "\n",
    "# 2. Segment Analysis\n",
    "segment_analysis = customer_summary.groupby('Segment').agg({\n",
    "    'Orders': ['count', 'mean'],\n",
    "    'Revenue': ['sum', 'mean'],\n",
    "    'DaysSinceLastOrder': 'mean'\n",
    "}).round(2)\n",
    "\n",
    "print(\"\\nSegment Analysis:\")\n",
    "print(segment_analysis)\n",
    "\n",
    "# 3. Top Customers\n",
    "top_customers = customer_summary.nlargest(5, 'Revenue')[['Orders', 'Revenue', 'Segment']]\n",
    "print(\"\\nTop 5 Customers:\")\n",
    "print(top_customers)\n",
    "\n",
    "# 4. Churn Risk\n",
    "churn_risk = customer_summary[customer_summary['DaysSinceLastOrder'] > 30].sort_values(\n",
    "    'Revenue', ascending=False\n",
    ").head(10)[['Orders', 'Revenue', 'DaysSinceLastOrder']]\n",
    "\n",
    "print(\"\\nChurn Risk (No order in 30+ days):\")\n",
    "print(churn_risk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project 2: Sales Performance Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìà SALES PERFORMANCE REPORT\n",
      "==================================================\n",
      "Monthly Performance:\n",
      "         Orders     Revenue  UniqueCustomers  Revenue_Growth      AOV\n",
      "Month                                                                \n",
      "2024-01     744  3747136.04              192             NaN  5036.47\n",
      "2024-02     256  1396758.63              148          -62.72  5456.09\n",
      "\n",
      "Product Performance:\n",
      "            Orders     Revenue  Units  Avg_Order_Value  Revenue_Share\n",
      "Product                                                              \n",
      "Headphones     204  1102167.99    985          5402.78          21.43\n",
      "Laptop         210  1099719.83   1097          5236.76          21.38\n",
      "Tablet         190  1011230.27    985          5322.26          19.66\n",
      "Phone          190   970814.44    943          5109.55          18.87\n",
      "Watch          206   959962.14   1004          4660.01          18.66\n",
      "\n",
      "City Performance:\n",
      "         TotalValue          OrderID\n",
      "                sum     mean   count\n",
      "City                                \n",
      "Chicago  1027717.20  5216.84     197\n",
      "Houston  1001581.91  4933.90     203\n",
      "LA       1082783.27  5729.01     189\n",
      "NYC       786825.35  4711.53     167\n",
      "Phoenix  1005767.09  5184.37     194\n",
      "\n",
      "üìä KEY METRICS\n",
      "==================================================\n",
      "Total Revenue: $5,143,894.67\n",
      "Total Orders: 1,000\n",
      "Unique Customers: 194\n",
      "Average Order Value: $5143.89\n",
      "Best Selling Product: Headphones\n",
      "Top City: LA\n"
     ]
    }
   ],
   "source": [
    "# Project 2: Sales Performance Report\n",
    "print(\"üìà SALES PERFORMANCE REPORT\\n\" + \"=\"*50)\n",
    "\n",
    "# Monthly trends\n",
    "monthly_sales = df.groupby('Month').agg({\n",
    "    'OrderID': 'count',\n",
    "    'TotalValue': 'sum',\n",
    "    'Customer': 'nunique'\n",
    "}).rename(columns={\n",
    "    'OrderID': 'Orders',\n",
    "    'TotalValue': 'Revenue',\n",
    "    'Customer': 'UniqueCustomers'\n",
    "})\n",
    "\n",
    "# Calculate growth\n",
    "monthly_sales['Revenue_Growth'] = monthly_sales['Revenue'].pct_change() * 100\n",
    "monthly_sales['AOV'] = monthly_sales['Revenue'] / monthly_sales['Orders']\n",
    "\n",
    "print(\"Monthly Performance:\")\n",
    "print(monthly_sales.round(2))\n",
    "\n",
    "# Product performance\n",
    "product_performance = df.groupby('Product').agg({\n",
    "    'OrderID': 'count',\n",
    "    'TotalValue': 'sum',\n",
    "    'Quantity': 'sum'\n",
    "}).rename(columns={\n",
    "    'OrderID': 'Orders',\n",
    "    'TotalValue': 'Revenue',\n",
    "    'Quantity': 'Units'\n",
    "})\n",
    "\n",
    "product_performance['Avg_Order_Value'] = (\n",
    "    product_performance['Revenue'] / product_performance['Orders']\n",
    ").round(2)\n",
    "\n",
    "product_performance['Revenue_Share'] = (\n",
    "    product_performance['Revenue'] / product_performance['Revenue'].sum() * 100\n",
    ").round(2)\n",
    "\n",
    "print(\"\\nProduct Performance:\")\n",
    "print(product_performance.sort_values('Revenue', ascending=False))\n",
    "\n",
    "# City performance\n",
    "city_performance = df.dropna(subset=['City']).groupby('City').agg({\n",
    "    'TotalValue': ['sum', 'mean'],\n",
    "    'OrderID': 'count'\n",
    "}).round(2)\n",
    "\n",
    "print(\"\\nCity Performance:\")\n",
    "print(city_performance)\n",
    "\n",
    "# Key Metrics\n",
    "print(\"\\nüìä KEY METRICS\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Total Revenue: ${df['TotalValue'].sum():,.2f}\")\n",
    "print(f\"Total Orders: {df['OrderID'].nunique():,}\")\n",
    "print(f\"Unique Customers: {df['Customer'].nunique()}\")\n",
    "print(f\"Average Order Value: ${df['TotalValue'].mean():.2f}\")\n",
    "print(f\"Best Selling Product: {product_performance.idxmax()['Revenue']}\")\n",
    "print(f\"Top City: {city_performance.idxmax()[('TotalValue', 'sum')]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéì Advanced Pandas Techniques\n",
    "\n",
    "### üöÄ Pro-Level Skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚õìÔ∏è Method Chaining\n",
      "========================================\n",
      "Top products by revenue (>$1000 orders only):\n",
      "               Revenue  Orders\n",
      "Product                       \n",
      "Headphones  1086799.37     177\n",
      "Laptop      1082285.48     179\n",
      "Tablet       999385.61     169\n",
      "Phone        955406.29     163\n",
      "Watch        939522.78     170\n"
     ]
    }
   ],
   "source": [
    "# Advanced: Method Chaining\n",
    "print(\"‚õìÔ∏è Method Chaining\\n\" + \"=\"*40)\n",
    "\n",
    "# Clean, elegant data processing\n",
    "result = (\n",
    "    sales_data\n",
    "    .assign(TotalValue=lambda x: x['Price'] * x['Quantity'])\n",
    "    .query('TotalValue > 1000')\n",
    "    .groupby('Product')\n",
    "    .agg({'TotalValue': 'sum', 'OrderID': 'count'})\n",
    "    .rename(columns={'TotalValue': 'Revenue', 'OrderID': 'Orders'})\n",
    "    .sort_values('Revenue', ascending=False)\n",
    "    .head()\n",
    ")\n",
    "\n",
    "print(\"Top products by revenue (>$1000 orders only):\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìö MultiIndex Operations\n",
      "========================================\n",
      "MultiIndex Series:\n",
      "City     Product   \n",
      "Chicago  Headphones    161110.31\n",
      "         Laptop        229577.32\n",
      "         Phone         221616.38\n",
      "         Tablet        179662.69\n",
      "         Watch         235750.50\n",
      "Houston  Headphones    229551.81\n",
      "         Laptop        200158.05\n",
      "         Phone         179512.09\n",
      "         Tablet        209217.30\n",
      "         Watch         183142.66\n",
      "Name: TotalValue, dtype: float64\n",
      "\n",
      "Access NYC data:\n",
      "Product\n",
      "Headphones    145896.87\n",
      "Laptop        137539.76\n",
      "Phone         190958.46\n",
      "Tablet        141657.38\n",
      "Watch         170772.88\n",
      "Name: TotalValue, dtype: float64\n",
      "\n",
      "Unstacked (Pivoted):\n",
      "Product  Headphones     Laptop      Phone     Tablet      Watch\n",
      "City                                                           \n",
      "Chicago   161110.31  229577.32  221616.38  179662.69  235750.50\n",
      "Houston   229551.81  200158.05  179512.09  209217.30  183142.66\n",
      "LA        211277.31  273845.84  202567.06  252482.33  142610.73\n",
      "NYC       145896.87  137539.76  190958.46  141657.38  170772.88\n",
      "Phoenix   326007.22  186218.20  145612.96  174129.13  173799.58\n"
     ]
    }
   ],
   "source": [
    "# Advanced: MultiIndex Operations\n",
    "print(\"üìö MultiIndex Operations\\n\" + \"=\"*40)\n",
    "\n",
    "# Create MultiIndex DataFrame\n",
    "multi_df = df.groupby(['City', 'Product'])['TotalValue'].sum().round(2)\n",
    "print(\"MultiIndex Series:\")\n",
    "print(multi_df.head(10))\n",
    "\n",
    "# Access MultiIndex data\n",
    "print(\"\\nAccess NYC data:\")\n",
    "print(multi_df.loc['NYC'])\n",
    "\n",
    "# Unstack to pivot\n",
    "pivoted = multi_df.unstack(fill_value=0)\n",
    "print(\"\\nUnstacked (Pivoted):\")\n",
    "print(pivoted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü™ü Window Functions\n",
      "========================================\n",
      "Window function results:\n",
      "      City     Product  TotalValue  Rank_in_City  Cumulative_City_Revenue  Pct_of_City_Total\n",
      "0      NYC       Watch     8825.67          25.0                  8825.67           1.121681\n",
      "1  Chicago  Headphones      737.13         183.0                   737.13           0.071725\n",
      "2  Phoenix      Tablet    13526.56          10.0                 13526.56           1.344900\n",
      "3      NYC  Headphones     2907.03         102.0                 11732.70           0.369463\n",
      "4      NYC  Headphones    11755.50           9.0                 23488.20           1.494042\n",
      "5       LA       Phone    11579.22          27.0                 11579.22           1.069394\n",
      "6  Phoenix      Tablet     1777.32         150.0                 15303.88           0.176713\n",
      "7      NaN      Tablet    12316.95           NaN                      NaN                NaN\n",
      "8      NYC      Tablet     4787.65          72.0                 28275.85           0.608477\n",
      "9  Phoenix  Headphones    12495.06          16.0                 27798.94           1.242341\n"
     ]
    }
   ],
   "source": [
    "# Advanced: Window Functions\n",
    "print(\"ü™ü Window Functions\\n\" + \"=\"*40)\n",
    "\n",
    "# Ranking within groups\n",
    "df['Rank_in_City'] = df.groupby('City')['TotalValue'].rank(method='dense', ascending=False)\n",
    "\n",
    "# Cumulative sum within groups\n",
    "df['Cumulative_City_Revenue'] = df.groupby('City')['TotalValue'].cumsum()\n",
    "\n",
    "# Percentage of group total\n",
    "df['Pct_of_City_Total'] = df.groupby('City')['TotalValue'].transform(lambda x: x / x.sum() * 100)\n",
    "\n",
    "print(\"Window function results:\")\n",
    "print(df[['City', 'Product', 'TotalValue', 'Rank_in_City', \n",
    "          'Cumulative_City_Revenue', 'Pct_of_City_Total']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üèÜ Final Challenge: Complete E-Commerce Analysis\n",
    "\n",
    "### Build a Complete Analytics Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ E-COMMERCE ANALYTICS PIPELINE\n",
      "==================================================\n",
      "üìä EXECUTIVE SUMMARY\n",
      "==================================================\n",
      "Total Revenue          $5,143,894.67\n",
      "Total Orders                    1000\n",
      "Unique Customers                 194\n",
      "Average Order Value         $5143.89\n",
      "Products Sold                   5014\n",
      "Conversion Rate                97.0%\n",
      "dtype: object\n",
      "\n",
      "üí∞ TOP CUSTOMER LIFETIME VALUES\n",
      "==================================================\n",
      "                   CLV  Orders  CustomerAge_Days  Avg_Order_Value\n",
      "Customer                                                         \n",
      "Customer_61   69797.85      10                41      6979.785000\n",
      "Customer_104  68279.90      11                37      6207.263636\n",
      "Customer_110  65688.77       7                39      9384.110000\n",
      "Customer_177  59990.64      10                39      5999.064000\n",
      "Customer_195  56244.70      10                40      5624.470000\n",
      "\n",
      "üì¶ PRODUCT ANALYTICS\n",
      "==================================================\n",
      "               Revenue  Units_Sold  Orders  Unique_Buyers  Avg_Price  Market_Share\n",
      "Product                                                                           \n",
      "Headphones  1102167.99         985     204            126    1118.95         21.43\n",
      "Laptop      1099719.83        1097     210            130    1002.48         21.38\n",
      "Phone        970814.44         943     190            113    1029.50         18.87\n",
      "Tablet      1011230.27         985     190            125    1026.63         19.66\n",
      "Watch        959962.14        1004     206            135     956.14         18.66\n",
      "\n",
      "‚è∞ TIME ANALYSIS\n",
      "==================================================\n",
      "Best Hours for Sales: [5, 20, 11]\n",
      "Best Day of Week: Saturday\n",
      "Weekend Revenue: $1,557,598.86\n",
      "Weekday Revenue: $3,586,295.81\n",
      "\n",
      "‚úÖ Analysis Complete!\n"
     ]
    }
   ],
   "source": [
    "# Final Project: E-Commerce Analytics Pipeline\n",
    "print(\"üéØ E-COMMERCE ANALYTICS PIPELINE\\n\" + \"=\"*50)\n",
    "\n",
    "class EcommerceAnalyzer:\n",
    "    def __init__(self, data):\n",
    "        self.data = data.copy()\n",
    "        self.prepare_data()\n",
    "    \n",
    "    def prepare_data(self):\n",
    "        \"\"\"Prepare and clean data\"\"\"\n",
    "        self.data['TotalValue'] = self.data['Price'] * self.data['Quantity']\n",
    "        self.data['Month'] = self.data['Date'].dt.to_period('M')\n",
    "        self.data['DayOfWeek'] = self.data['Date'].dt.day_name()\n",
    "        self.data['Hour'] = self.data['Date'].dt.hour\n",
    "    \n",
    "    def executive_summary(self):\n",
    "        \"\"\"Generate executive summary\"\"\"\n",
    "        summary = {\n",
    "            'Total Revenue': f\"${self.data['TotalValue'].sum():,.2f}\",\n",
    "            'Total Orders': self.data['OrderID'].nunique(),\n",
    "            'Unique Customers': self.data['Customer'].nunique(),\n",
    "            'Average Order Value': f\"${self.data['TotalValue'].mean():.2f}\",\n",
    "            'Products Sold': self.data['Quantity'].sum(),\n",
    "            'Conversion Rate': f\"{(self.data['Customer'].nunique() / 200 * 100):.1f}%\"\n",
    "        }\n",
    "        return pd.Series(summary)\n",
    "    \n",
    "    def customer_lifetime_value(self):\n",
    "        \"\"\"Calculate CLV\"\"\"\n",
    "        clv = self.data.groupby('Customer').agg({\n",
    "            'TotalValue': 'sum',\n",
    "            'OrderID': 'count',\n",
    "            'Date': lambda x: (self.data['Date'].max() - x.min()).days\n",
    "        }).rename(columns={\n",
    "            'TotalValue': 'CLV',\n",
    "            'OrderID': 'Orders',\n",
    "            'Date': 'CustomerAge_Days'\n",
    "        })\n",
    "        \n",
    "        clv['Avg_Order_Value'] = clv['CLV'] / clv['Orders']\n",
    "        return clv.sort_values('CLV', ascending=False)\n",
    "    \n",
    "    def product_analytics(self):\n",
    "        \"\"\"Product performance analysis\"\"\"\n",
    "        products = self.data.groupby('Product').agg({\n",
    "            'TotalValue': 'sum',\n",
    "            'Quantity': 'sum',\n",
    "            'OrderID': 'count',\n",
    "            'Customer': 'nunique'\n",
    "        }).rename(columns={\n",
    "            'TotalValue': 'Revenue',\n",
    "            'Quantity': 'Units_Sold',\n",
    "            'OrderID': 'Orders',\n",
    "            'Customer': 'Unique_Buyers'\n",
    "        })\n",
    "        \n",
    "        products['Avg_Price'] = products['Revenue'] / products['Units_Sold']\n",
    "        products['Market_Share'] = products['Revenue'] / products['Revenue'].sum() * 100\n",
    "        \n",
    "        return products.round(2)\n",
    "    \n",
    "    def time_analysis(self):\n",
    "        \"\"\"Time-based patterns\"\"\"\n",
    "        # Best hours\n",
    "        hourly = self.data.groupby('Hour')['TotalValue'].agg(['sum', 'count'])\n",
    "        best_hours = hourly.nlargest(3, 'sum')\n",
    "        \n",
    "        # Best days\n",
    "        daily = self.data.groupby('DayOfWeek')['TotalValue'].sum()\n",
    "        best_day = daily.idxmax()\n",
    "        \n",
    "        return {\n",
    "            'Best Hours': best_hours.index.tolist(),\n",
    "            'Best Day': best_day,\n",
    "            'Weekend vs Weekday': {\n",
    "                'Weekend': daily[['Saturday', 'Sunday']].sum(),\n",
    "                'Weekday': daily[['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday']].sum()\n",
    "            }\n",
    "        }\n",
    "\n",
    "# Run the analysis\n",
    "analyzer = EcommerceAnalyzer(sales_data)\n",
    "\n",
    "print(\"üìä EXECUTIVE SUMMARY\")\n",
    "print(\"=\" * 50)\n",
    "print(analyzer.executive_summary())\n",
    "\n",
    "print(\"\\nüí∞ TOP CUSTOMER LIFETIME VALUES\")\n",
    "print(\"=\" * 50)\n",
    "print(analyzer.customer_lifetime_value().head())\n",
    "\n",
    "print(\"\\nüì¶ PRODUCT ANALYTICS\")\n",
    "print(\"=\" * 50)\n",
    "print(analyzer.product_analytics())\n",
    "\n",
    "print(\"\\n‚è∞ TIME ANALYSIS\")\n",
    "print(\"=\" * 50)\n",
    "time_insights = analyzer.time_analysis()\n",
    "print(f\"Best Hours for Sales: {time_insights['Best Hours']}\")\n",
    "print(f\"Best Day of Week: {time_insights['Best Day']}\")\n",
    "print(f\"Weekend Revenue: ${time_insights['Weekend vs Weekday']['Weekend']:,.2f}\")\n",
    "print(f\"Weekday Revenue: ${time_insights['Weekend vs Weekday']['Weekday']:,.2f}\")\n",
    "\n",
    "print(\"\\n‚úÖ Analysis Complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéØ Summary & Next Steps\n",
    "\n",
    "### üèÜ What You've Mastered:\n",
    "\n",
    "‚úÖ **Data Structures**\n",
    "- Series and DataFrames\n",
    "- MultiIndex operations\n",
    "\n",
    "‚úÖ **Data Manipulation**\n",
    "- Indexing and selection\n",
    "- Filtering and boolean indexing\n",
    "- Apply, map, and transform\n",
    "\n",
    "‚úÖ **Data Cleaning**\n",
    "- Missing data handling\n",
    "- Duplicate removal\n",
    "- Type conversions\n",
    "\n",
    "‚úÖ **Data Analysis**\n",
    "- GroupBy operations\n",
    "- Aggregations\n",
    "- Pivot tables\n",
    "\n",
    "‚úÖ **Data Combination**\n",
    "- Merging and joining\n",
    "- Concatenation\n",
    "\n",
    "‚úÖ **Time Series**\n",
    "- Date operations\n",
    "- Resampling\n",
    "- Rolling windows\n",
    "\n",
    "‚úÖ **Real-World Applications**\n",
    "- Customer analytics\n",
    "- Sales performance\n",
    "- E-commerce analysis\n",
    "\n",
    "### üöÄ Next Steps:\n",
    "\n",
    "1. **Practice with Real Datasets**: Kaggle, UCI ML Repository\n",
    "2. **Learn Visualization**: Matplotlib, Seaborn, Plotly\n",
    "3. **SQL Integration**: Read/write from databases\n",
    "4. **Big Data**: Dask, PySpark for larger datasets\n",
    "5. **Machine Learning**: Feed data to scikit-learn\n",
    "\n",
    "### üí° Pro Tips:\n",
    "\n",
    "- **Use vectorized operations** instead of loops\n",
    "- **Chain methods** for cleaner code\n",
    "- **Profile memory usage** with `.memory_usage()`\n",
    "- **Use categories** for string columns to save memory\n",
    "- **Read documentation**: pandas.pydata.org\n",
    "\n",
    "### üìö Resources:\n",
    "\n",
    "- Official Pandas Documentation\n",
    "- Pandas Cookbook by Ted Petrou\n",
    "- Python for Data Analysis by Wes McKinney\n",
    "- Kaggle Learn Pandas Course\n",
    "\n",
    "---\n",
    "\n",
    "## üéâ Congratulations!\n",
    "\n",
    "You've mastered Pandas - the Swiss Army knife of data analysis!\n",
    "\n",
    "With Pandas, you can now:\n",
    "- **Clean messy data** üßπ\n",
    "- **Analyze complex datasets** üìä\n",
    "- **Generate business insights** üí°\n",
    "- **Prepare data for ML** ü§ñ\n",
    "- **Create reports** üìà\n",
    "\n",
    "**Keep practicing, keep analyzing, and keep discovering insights with Pandas!** üêº"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéäüéäüéäüéäüéäüéäüéäüéäüéäüéäüéäüéäüéäüéäüéäüéäüéäüéäüéäüéä\n",
      "\n",
      "    üèÜ PANDAS MASTERY ACHIEVED! üèÜ\n",
      "\n",
      "    You're now ready to:\n",
      "    ‚Üí Analyze any dataset\n",
      "    ‚Üí Clean messy data\n",
      "    ‚Üí Generate insights\n",
      "    ‚Üí Build data pipelines\n",
      "\n",
      "    Next: Visualization with Matplotlib! üìà\n",
      "\n",
      "üéäüéäüéäüéäüéäüéäüéäüéäüéäüéäüéäüéäüéäüéäüéäüéäüéäüéäüéäüéä\n"
     ]
    }
   ],
   "source": [
    "# üéä Course Complete!\n",
    "print(\"üéä\" * 20)\n",
    "print(\"\\n    üèÜ PANDAS MASTERY ACHIEVED! üèÜ\")\n",
    "print(\"\\n    You're now ready to:\")\n",
    "print(\"    ‚Üí Analyze any dataset\")\n",
    "print(\"    ‚Üí Clean messy data\")\n",
    "print(\"    ‚Üí Generate insights\")\n",
    "print(\"    ‚Üí Build data pipelines\")\n",
    "print(\"\\n    Next: Visualization with Matplotlib! üìà\")\n",
    "print(\"\\n\" + \"üéä\" * 20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
